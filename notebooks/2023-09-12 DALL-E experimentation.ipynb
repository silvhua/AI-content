{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Title\n",
    "[]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\custom_python\")\n",
    "from silvhua import *\n",
    "# from datetime import datetime\n",
    "# sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\portfolio-projects\\online-PT-social-media-NLP\\src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the option to wrap text within cells\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "# pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', 20)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = dict()\n",
    "descriptions = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "poem = \"\"\"\n",
    "# Strength Training Mom\n",
    "\n",
    "A mom's job is never done,\n",
    "From sunrise to setting sun,\n",
    "Her strength tested every day,\n",
    "Tough moments always come her way.\n",
    "\n",
    "But with strength training in her life,\n",
    "She can handle any strife,\n",
    "Lifting weights, building muscle,\n",
    "Makes her feel like she can hustle.\n",
    "\n",
    "Stronger body, stronger mind,\n",
    "More energy to unwind,\n",
    "Patient, loving, and kind,\n",
    "A better mom you'll find.\n",
    "\n",
    "So moms, don't be afraid,\n",
    "To lift weights and upgrade,\n",
    "Your strength will make you great,\n",
    "A superhero mom, first rate!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iteration 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: input_variables=['image_desc'] output_parser=None partial_variables={} template='Generate a detailed prompt to generate an image based on the following social media post: {image_desc}' template_format='f-string' validate_template=True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'description': 'I like computers and reading.',\n",
       " 'prompt': PromptTemplate(input_variables=['image_desc'], output_parser=None, partial_variables={}, template='Generate a detailed prompt to generate an image based on the following social media post: {image_desc}', template_format='f-string', validate_template=True)}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "import os\n",
    "from langchain.utilities.dalle_image_generator import DallEAPIWrapper\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "def get_dalle_image(description, temperature=1, template=None):\n",
    "    llm = OpenAI(temperature=temperature, openai_organization=os.environ['openai_organization'])\n",
    "    description = description.strip()\n",
    "    if template:\n",
    "        template=template + ': {image_desc}'\n",
    "    else:\n",
    "        template=\"Generate a detailed prompt to generate an image based on the following social media post: {image_desc}\"\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"image_desc\"],\n",
    "        template=template,\n",
    "    )\n",
    "    print(f'Prompt: {prompt}')\n",
    "    chain = LLMChain(llm=llm, prompt=prompt)\n",
    "    # image_url = DallEAPIWrapper().run(chain.run(\"halloween night at a haunted museum\"))\n",
    "    results = {\n",
    "        # 'image_url': image_url, \n",
    "        'description': description,\n",
    "        'prompt': prompt\n",
    "        }\n",
    "    return results\n",
    "\n",
    "iteration = 1\n",
    "description = \"\"\"\n",
    "I like computers and reading.\n",
    "\"\"\"\n",
    "results_dict[iteration] = get_dalle_image(description)\n",
    "results_dict[iteration]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: input_variables=['image_desc'] output_parser=None partial_variables={} template='Generate a detailed prompt to generate an image based on the following description: {image_desc}' template_format='f-string' validate_template=True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'description': 'I like computers and reading.',\n",
       " 'prompt': PromptTemplate(input_variables=['image_desc'], output_parser=None, partial_variables={}, template='Generate a detailed prompt to generate an image based on the following description: {image_desc}', template_format='f-string', validate_template=True)}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iteration = 1.1\n",
    "description = \"\"\"\n",
    "I like computers and reading.\n",
    "\"\"\"\n",
    "template = \"Generate a detailed prompt to generate an image based on the following description\"\n",
    "results_dict[iteration] = get_dalle_image(description, template=template)\n",
    "results_dict[iteration]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt template: Generate a detailed prompt to generate an image based on the following social media post: {image_desc}\n",
      "\n",
      "Input: # Strength Training Mom\n",
      "\n",
      "A mom's job is never done,\n",
      "From sunrise to setting sun,\n",
      "Her strength tested every day,\n",
      "Tough moments always come her way.\n",
      "\n",
      "But with strength training in her life,\n",
      "She can handle any strife,\n",
      "Lifting weights, building muscle,\n",
      "Makes her feel like she can hustle.\n",
      "\n",
      "Stronger body, stronger mind,\n",
      "More energy to unwind,\n",
      "Patient, loving, and kind,\n",
      "A better mom you'll find.\n",
      "\n",
      "So moms, don't be afraid,\n",
      "To lift weights and upgrade,\n",
      "Your strength will make you great,\n",
      "A superhero mom, first rate!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'image_url': 'https://oaidalleapiprodscus.blob.core.windows.net/private/org-abUfYkwR7vFsTFp1p0qZ6YtJ/user-RXAiHh79huihhcA5ecHTcKIh/img-JzqywIO0VQDg9N4ejLzit9Op.png?st=2023-09-12T23%3A09%3A58Z&se=2023-09-13T01%3A09%3A58Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2023-09-12T23%3A52%3A51Z&ske=2023-09-13T23%3A52%3A51Z&sks=b&skv=2021-08-06&sig=bxiHvGnyWRCaN6znEd4EWVqSDmu7REv6KOGYhJcfXRo%3D',\n",
       " 'description': \"# Strength Training Mom\\n\\nA mom's job is never done,\\nFrom sunrise to setting sun,\\nHer strength tested every day,\\nTough moments always come her way.\\n\\nBut with strength training in her life,\\nShe can handle any strife,\\nLifting weights, building muscle,\\nMakes her feel like she can hustle.\\n\\nStronger body, stronger mind,\\nMore energy to unwind,\\nPatient, loving, and kind,\\nA better mom you'll find.\\n\\nSo moms, don't be afraid,\\nTo lift weights and upgrade,\\nYour strength will make you great,\\nA superhero mom, first rate!\",\n",
       " 'prompt': PromptTemplate(input_variables=['image_desc'], output_parser=None, partial_variables={}, template='Generate a detailed prompt to generate an image based on the following social media post: {image_desc}', template_format='f-string', validate_template=True)}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "import os\n",
    "from langchain.utilities.dalle_image_generator import DallEAPIWrapper\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "def get_dalle_image(description, temperature=1, template=None):\n",
    "    llm = OpenAI(temperature=temperature, openai_organization=os.environ['openai_organization'])\n",
    "    description = description.strip()\n",
    "    if template:\n",
    "        template=template + ': {image_desc}'\n",
    "    else:\n",
    "        template=\"Generate a detailed prompt to generate an image based on the following social media post: {image_desc}\"\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"image_desc\"],\n",
    "        template=template,\n",
    "    )\n",
    "    print(f'Prompt template: {prompt.template}')\n",
    "    print(f'\\nInput: {description}')\n",
    "    chain = LLMChain(llm=llm, prompt=prompt)\n",
    "    image_url = DallEAPIWrapper().run(chain.run(\"halloween night at a haunted museum\"))\n",
    "    results = {\n",
    "        'image_url': image_url, \n",
    "        'description': description,\n",
    "        'prompt': prompt\n",
    "        }\n",
    "    return results\n",
    "\n",
    "iteration = 1.2\n",
    "descriptions[1] = \"\"\"\n",
    "I like computers and reading.\n",
    "\"\"\"\n",
    "descriptions[2] = poem\n",
    "results_dict[iteration] = get_dalle_image(descriptions[2])\n",
    "results_dict[iteration]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iteration 2 show the prompt generated for DALL-E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt template: Generate a detailed prompt to generate an image based on the following social media post: {image_desc}\n",
      "\n",
      "Input: # Strength Training Mom\n",
      "\n",
      "A mom's job is never done,\n",
      "From sunrise to setting sun,\n",
      "Her strength tested every day,\n",
      "Tough moments always come her way.\n",
      "\n",
      "But with strength training in her life,\n",
      "She can handle any strife,\n",
      "Lifting weights, building muscle,\n",
      "Makes her feel like she can hustle.\n",
      "\n",
      "Stronger body, stronger mind,\n",
      "More energy to unwind,\n",
      "Patient, loving, and kind,\n",
      "A better mom you'll find.\n",
      "\n",
      "So moms, don't be afraid,\n",
      "To lift weights and upgrade,\n",
      "Your strength will make you great,\n",
      "A superhero mom, first rate!\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mGenerate a detailed prompt to generate an image based on the following social media post: halloween night at a haunted museum\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'image_url': 'https://oaidalleapiprodscus.blob.core.windows.net/private/org-abUfYkwR7vFsTFp1p0qZ6YtJ/user-RXAiHh79huihhcA5ecHTcKIh/img-PgFcZcUxf31HUqRrqiPAlvQ7.png?st=2023-09-12T23%3A15%3A57Z&se=2023-09-13T01%3A15%3A57Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2023-09-12T23%3A52%3A36Z&ske=2023-09-13T23%3A52%3A36Z&sks=b&skv=2021-08-06&sig=DM3nNtrxmTxwI6ojoi8NzyCf1qirfUJUvg1GgoQFEJw%3D',\n",
       " 'description': \"# Strength Training Mom\\n\\nA mom's job is never done,\\nFrom sunrise to setting sun,\\nHer strength tested every day,\\nTough moments always come her way.\\n\\nBut with strength training in her life,\\nShe can handle any strife,\\nLifting weights, building muscle,\\nMakes her feel like she can hustle.\\n\\nStronger body, stronger mind,\\nMore energy to unwind,\\nPatient, loving, and kind,\\nA better mom you'll find.\\n\\nSo moms, don't be afraid,\\nTo lift weights and upgrade,\\nYour strength will make you great,\\nA superhero mom, first rate!\",\n",
       " 'prompt': PromptTemplate(input_variables=['image_desc'], output_parser=None, partial_variables={}, template='Generate a detailed prompt to generate an image based on the following social media post: {image_desc}', template_format='f-string', validate_template=True)}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "import os\n",
    "from langchain.utilities.dalle_image_generator import DallEAPIWrapper\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "def get_dalle_image(description, temperature=1, template=None):\n",
    "    llm = OpenAI(temperature=temperature, openai_organization=os.environ['openai_organization'])\n",
    "    description = description.strip()\n",
    "    if template:\n",
    "        template=template + ': {image_desc}'\n",
    "    else:\n",
    "        template=\"Generate a detailed prompt to generate an image based on the following social media post: {image_desc}\"\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"image_desc\"],\n",
    "        template=template,\n",
    "    )\n",
    "    print(f'Prompt template: {prompt.template}')\n",
    "    print(f'\\nInput: {description}')\n",
    "    chain = LLMChain(llm=llm, prompt=prompt, verbose=True)\n",
    "    image_url = DallEAPIWrapper().run(chain.run(\"halloween night at a haunted museum\"))\n",
    "    results = {\n",
    "        'image_url': image_url, \n",
    "        'description': description,\n",
    "        'prompt': prompt\n",
    "        }\n",
    "    return results\n",
    "\n",
    "iteration = 2\n",
    "descriptions[1] = \"\"\"\n",
    "I like computers and reading.\n",
    "\"\"\"\n",
    "descriptions[2] = poem\n",
    "results_dict[iteration] = get_dalle_image(descriptions[2])\n",
    "results_dict[iteration]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt template: Generate a detailed prompt to generate an image based on the following social media post: {image_desc}\n",
      "\n",
      "Input: # Strength Training Mom\n",
      "\n",
      "A mom's job is never done,\n",
      "From sunrise to setting sun,\n",
      "Her strength tested every day,\n",
      "Tough moments always come her way.\n",
      "\n",
      "But with strength training in her life,\n",
      "She can handle any strife,\n",
      "Lifting weights, building muscle,\n",
      "Makes her feel like she can hustle.\n",
      "\n",
      "Stronger body, stronger mind,\n",
      "More energy to unwind,\n",
      "Patient, loving, and kind,\n",
      "A better mom you'll find.\n",
      "\n",
      "So moms, don't be afraid,\n",
      "To lift weights and upgrade,\n",
      "Your strength will make you great,\n",
      "A superhero mom, first rate!\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mGenerate a detailed prompt to generate an image based on the following social media post: # Strength Training Mom\n",
      "\n",
      "A mom's job is never done,\n",
      "From sunrise to setting sun,\n",
      "Her strength tested every day,\n",
      "Tough moments always come her way.\n",
      "\n",
      "But with strength training in her life,\n",
      "She can handle any strife,\n",
      "Lifting weights, building muscle,\n",
      "Makes her feel like she can hustle.\n",
      "\n",
      "Stronger body, stronger mind,\n",
      "More energy to unwind,\n",
      "Patient, loving, and kind,\n",
      "A better mom you'll find.\n",
      "\n",
      "So moms, don't be afraid,\n",
      "To lift weights and upgrade,\n",
      "Your strength will make you great,\n",
      "A superhero mom, first rate!\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'image_url': 'https://oaidalleapiprodscus.blob.core.windows.net/private/org-abUfYkwR7vFsTFp1p0qZ6YtJ/user-RXAiHh79huihhcA5ecHTcKIh/img-7QOPaoPwopky3vwqznrb9ryV.png?st=2023-09-12T23%3A18%3A30Z&se=2023-09-13T01%3A18%3A30Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2023-09-13T00%3A02%3A50Z&ske=2023-09-14T00%3A02%3A50Z&sks=b&skv=2021-08-06&sig=GLqdMKvW5ozjQWepMpzJ9o1C27hkPl7GWHuMDvnQZzA%3D',\n",
       " 'description': \"# Strength Training Mom\\n\\nA mom's job is never done,\\nFrom sunrise to setting sun,\\nHer strength tested every day,\\nTough moments always come her way.\\n\\nBut with strength training in her life,\\nShe can handle any strife,\\nLifting weights, building muscle,\\nMakes her feel like she can hustle.\\n\\nStronger body, stronger mind,\\nMore energy to unwind,\\nPatient, loving, and kind,\\nA better mom you'll find.\\n\\nSo moms, don't be afraid,\\nTo lift weights and upgrade,\\nYour strength will make you great,\\nA superhero mom, first rate!\",\n",
       " 'prompt': PromptTemplate(input_variables=['image_desc'], output_parser=None, partial_variables={}, template='Generate a detailed prompt to generate an image based on the following social media post: {image_desc}', template_format='f-string', validate_template=True)}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "import os\n",
    "from langchain.utilities.dalle_image_generator import DallEAPIWrapper\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "def get_dalle_image(description, temperature=1, template=None):\n",
    "    llm = OpenAI(temperature=temperature, openai_organization=os.environ['openai_organization'])\n",
    "    description = description.strip()\n",
    "    if template:\n",
    "        template=template + ': {image_desc}'\n",
    "    else:\n",
    "        template=\"Generate a detailed prompt to generate an image based on the following social media post: {image_desc}\"\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"image_desc\"],\n",
    "        template=template,\n",
    "    )\n",
    "    print(f'Prompt template: {prompt.template}')\n",
    "    print(f'\\nInput: {description}')\n",
    "    chain = LLMChain(llm=llm, prompt=prompt, verbose=True)\n",
    "    image_url = DallEAPIWrapper().run(chain.run(description))\n",
    "    results = {\n",
    "        'image_url': image_url, \n",
    "        'description': description,\n",
    "        'prompt': prompt\n",
    "        }\n",
    "    return results\n",
    "\n",
    "iteration = 2\n",
    "descriptions[1] = \"\"\"\n",
    "I like computers and reading.\n",
    "\"\"\"\n",
    "descriptions[2] = poem\n",
    "results_dict[iteration] = get_dalle_image(descriptions[2])\n",
    "results_dict[iteration]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Show the image prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt template: Generate a detailed prompt to generate an image based on the following social media post: {image_desc}\n",
      "\n",
      "Input: # Strength Training Mom\n",
      "\n",
      "A mom's job is never done,\n",
      "From sunrise to setting sun,\n",
      "Her strength tested every day,\n",
      "Tough moments always come her way.\n",
      "\n",
      "But with strength training in her life,\n",
      "She can handle any strife,\n",
      "Lifting weights, building muscle,\n",
      "Makes her feel like she can hustle.\n",
      "\n",
      "Stronger body, stronger mind,\n",
      "More energy to unwind,\n",
      "Patient, loving, and kind,\n",
      "A better mom you'll find.\n",
      "\n",
      "So moms, don't be afraid,\n",
      "To lift weights and upgrade,\n",
      "Your strength will make you great,\n",
      "A superhero mom, first rate!\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mGenerate a detailed prompt to generate an image based on the following social media post: # Strength Training Mom\n",
      "\n",
      "A mom's job is never done,\n",
      "From sunrise to setting sun,\n",
      "Her strength tested every day,\n",
      "Tough moments always come her way.\n",
      "\n",
      "But with strength training in her life,\n",
      "She can handle any strife,\n",
      "Lifting weights, building muscle,\n",
      "Makes her feel like she can hustle.\n",
      "\n",
      "Stronger body, stronger mind,\n",
      "More energy to unwind,\n",
      "Patient, loving, and kind,\n",
      "A better mom you'll find.\n",
      "\n",
      "So moms, don't be afraid,\n",
      "To lift weights and upgrade,\n",
      "Your strength will make you great,\n",
      "A superhero mom, first rate!\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'image_url': 'https://oaidalleapiprodscus.blob.core.windows.net/private/org-abUfYkwR7vFsTFp1p0qZ6YtJ/user-RXAiHh79huihhcA5ecHTcKIh/img-0fRvAkPg3P3VFiUxndBf4T29.png?st=2023-09-16T21%3A25%3A44Z&se=2023-09-16T23%3A25%3A44Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2023-09-15T23%3A11%3A45Z&ske=2023-09-16T23%3A11%3A45Z&sks=b&skv=2021-08-06&sig=MWIxd/BETYwJim40FWCdjXzrU7lAfr1/6BQBWDosPaQ%3D',\n",
       " 'description': \"# Strength Training Mom\\n\\nA mom's job is never done,\\nFrom sunrise to setting sun,\\nHer strength tested every day,\\nTough moments always come her way.\\n\\nBut with strength training in her life,\\nShe can handle any strife,\\nLifting weights, building muscle,\\nMakes her feel like she can hustle.\\n\\nStronger body, stronger mind,\\nMore energy to unwind,\\nPatient, loving, and kind,\\nA better mom you'll find.\\n\\nSo moms, don't be afraid,\\nTo lift weights and upgrade,\\nYour strength will make you great,\\nA superhero mom, first rate!\",\n",
       " 'prompt': PromptTemplate(input_variables=['image_desc'], output_parser=None, partial_variables={}, template='Generate a detailed prompt to generate an image based on the following social media post: {image_desc}', template_format='f-string', validate_template=True),\n",
       " 'image_prompt': '\\n\\nPrompt:\\nAn image of a mom strength training with a determined yet peaceful look on her face. She is lifting weights and is wearing a comfortable and supportive workout outfit that she feels amazing in. Light is streaming through a window behind her, flooding the space with warmth and sunshine. The inspiring message from the social media post can be visually incorporated into the image – perhaps with a quote included in the background, or with the mom looking off into the distance, radiating determination and confidence.'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "import os\n",
    "from langchain.utilities.dalle_image_generator import DallEAPIWrapper\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "def get_dalle_image(description, temperature=1, template=None):\n",
    "    llm = OpenAI(temperature=temperature, openai_organization=os.environ['openai_organization'])\n",
    "    description = description.strip()\n",
    "    if template:\n",
    "        template=template + ': {image_desc}'\n",
    "    else:\n",
    "        template=\"Generate a detailed prompt to generate an image based on the following social media post: {image_desc}\"\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"image_desc\"],\n",
    "        template=template,\n",
    "    )\n",
    "    print(f'Prompt template: {prompt.template}')\n",
    "    print(f'\\nInput: {description}')\n",
    "    chain = LLMChain(llm=llm, prompt=prompt, verbose=True)\n",
    "    image_prompt = chain.run(description)\n",
    "    image_url = DallEAPIWrapper().run(image_prompt)\n",
    "    results = {\n",
    "        'image_url': image_url, \n",
    "        'description': description,\n",
    "        'prompt': prompt,\n",
    "        'image_prompt': image_prompt\n",
    "        }\n",
    "    return results\n",
    "\n",
    "iteration = 2\n",
    "descriptions[1] = \"\"\"\n",
    "I like computers and reading.\n",
    "\"\"\"\n",
    "descriptions[2] = poem\n",
    "results_dict[iteration] = get_dalle_image(descriptions[2])\n",
    "results_dict[iteration]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Prompt:\n",
      "An image of a mom strength training with a determined yet peaceful look on her face. She is lifting weights and is wearing a comfortable and supportive workout outfit that she feels amazing in. Light is streaming through a window behind her, flooding the space with warmth and sunshine. The inspiring message from the social media post can be visually incorporated into the image – perhaps with a quote included in the background, or with the mom looking off into the distance, radiating determination and confidence.\n"
     ]
    }
   ],
   "source": [
    "print(results_dict[iteration]['image_prompt'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt template: Generate a detailed prompt to generate an image based on the following social media post: {image_desc}\n",
      "\n",
      "Input: # Strength Training Mom\n",
      "\n",
      "A mom's job is never done,\n",
      "From sunrise to setting sun,\n",
      "Her strength tested every day,\n",
      "Tough moments always come her way.\n",
      "\n",
      "But with strength training in her life,\n",
      "She can handle any strife,\n",
      "Lifting weights, building muscle,\n",
      "Makes her feel like she can hustle.\n",
      "\n",
      "Stronger body, stronger mind,\n",
      "More energy to unwind,\n",
      "Patient, loving, and kind,\n",
      "A better mom you'll find.\n",
      "\n",
      "So moms, don't be afraid,\n",
      "To lift weights and upgrade,\n",
      "Your strength will make you great,\n",
      "A superhero mom, first rate!\n",
      "\n",
      "Image prompt: Create an image of a mom lifting weights in the gym, with a determined expression on her face and a look of strength and power. She should be wearing workout clothes and have a towel draped over her shoulders. The background should be a gym, with other people working out and weights scattered around. The caption should read: #StrengthTrainingMom - Showing the world that moms can be strong too!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'image_url': 'https://oaidalleapiprodscus.blob.core.windows.net/private/org-abUfYkwR7vFsTFp1p0qZ6YtJ/user-RXAiHh79huihhcA5ecHTcKIh/img-zmEtUczB442cy2UT9hL8leIx.png?st=2023-09-16T21%3A37%3A21Z&se=2023-09-16T23%3A37%3A21Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2023-09-15T23%3A07%3A08Z&ske=2023-09-16T23%3A07%3A08Z&sks=b&skv=2021-08-06&sig=CfJ8kW6OudRUtfQEF5yCqTviaV9yypcSy7ng37F9%2Bgg%3D',\n",
       " 'description': \"# Strength Training Mom\\n\\nA mom's job is never done,\\nFrom sunrise to setting sun,\\nHer strength tested every day,\\nTough moments always come her way.\\n\\nBut with strength training in her life,\\nShe can handle any strife,\\nLifting weights, building muscle,\\nMakes her feel like she can hustle.\\n\\nStronger body, stronger mind,\\nMore energy to unwind,\\nPatient, loving, and kind,\\nA better mom you'll find.\\n\\nSo moms, don't be afraid,\\nTo lift weights and upgrade,\\nYour strength will make you great,\\nA superhero mom, first rate!\",\n",
       " 'prompt': PromptTemplate(input_variables=['image_desc'], output_parser=None, partial_variables={}, template='Generate a detailed prompt to generate an image based on the following social media post: {image_desc}', template_format='f-string', validate_template=True),\n",
       " 'image_prompt': 'Create an image of a mom lifting weights in the gym, with a determined expression on her face and a look of strength and power. She should be wearing workout clothes and have a towel draped over her shoulders. The background should be a gym, with other people working out and weights scattered around. The caption should read: #StrengthTrainingMom - Showing the world that moms can be strong too!'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "import os\n",
    "from langchain.utilities.dalle_image_generator import DallEAPIWrapper\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "def get_dalle_image(description, temperature=1, template=None, verbose=False):\n",
    "    llm = OpenAI(temperature=temperature, openai_organization=os.environ['openai_organization'])\n",
    "    description = description.strip()\n",
    "    if template:\n",
    "        template=template + ': {image_desc}'\n",
    "    else:\n",
    "        template=\"Generate a detailed prompt to generate an image based on the following social media post: {image_desc}\"\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"image_desc\"],\n",
    "        template=template,\n",
    "    )\n",
    "    print(f'Prompt template: {prompt.template}')\n",
    "    print(f'\\nInput: {description}')\n",
    "    chain = LLMChain(llm=llm, prompt=prompt, verbose=verbose)\n",
    "    image_prompt = chain.run(description).strip()\n",
    "    print(f'\\nImage prompt: {image_prompt}')\n",
    "    image_url = DallEAPIWrapper().run(image_prompt)\n",
    "    results = {\n",
    "        'image_url': image_url, \n",
    "        'description': description,\n",
    "        'prompt': prompt,\n",
    "        'image_prompt': image_prompt\n",
    "        }\n",
    "    return results\n",
    "\n",
    "iteration = 2.21\n",
    "\n",
    "descriptions[2] = poem\n",
    "results_dict[iteration] = get_dalle_image(descriptions[2], temperature=0)\n",
    "results_dict[iteration]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Update number of images to generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt template: Generate a detailed prompt to generate an image based on the following social media post: {image_desc}\n",
      "\n",
      "Input: # Strength Training Mom\n",
      "\n",
      "A mom's job is never done,\n",
      "From sunrise to setting sun,\n",
      "Her strength tested every day,\n",
      "Tough moments always come her way.\n",
      "\n",
      "But with strength training in her life,\n",
      "She can handle any strife,\n",
      "Lifting weights, building muscle,\n",
      "Makes her feel like she can hustle.\n",
      "\n",
      "Stronger body, stronger mind,\n",
      "More energy to unwind,\n",
      "Patient, loving, and kind,\n",
      "A better mom you'll find.\n",
      "\n",
      "So moms, don't be afraid,\n",
      "To lift weights and upgrade,\n",
      "Your strength will make you great,\n",
      "A superhero mom, first rate!\n",
      "\n",
      "Image prompt: Create an image of a mom lifting weights in the gym, with a determined expression on her face and a look of strength and power. She should be wearing workout clothes and have a towel draped over her shoulders. The background should be a gym with other people working out. The caption should read: #StrengthTrainingMom - A mom's job is never done, but with strength training she can handle any strife!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'image_url': 'https://oaidalleapiprodscus.blob.core.windows.net/private/org-abUfYkwR7vFsTFp1p0qZ6YtJ/user-RXAiHh79huihhcA5ecHTcKIh/img-IWNebYx00yL0wCTfPAqrn8GT.png?st=2023-09-16T21%3A43%3A07Z&se=2023-09-16T23%3A43%3A07Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2023-09-15T23%3A07%3A57Z&ske=2023-09-16T23%3A07%3A57Z&sks=b&skv=2021-08-06&sig=SYoYsRVfzwppkfQMnY6tiSK/tG%2BxblKHy1/ixB/RUc4%3D',\n",
       " 'description': \"# Strength Training Mom\\n\\nA mom's job is never done,\\nFrom sunrise to setting sun,\\nHer strength tested every day,\\nTough moments always come her way.\\n\\nBut with strength training in her life,\\nShe can handle any strife,\\nLifting weights, building muscle,\\nMakes her feel like she can hustle.\\n\\nStronger body, stronger mind,\\nMore energy to unwind,\\nPatient, loving, and kind,\\nA better mom you'll find.\\n\\nSo moms, don't be afraid,\\nTo lift weights and upgrade,\\nYour strength will make you great,\\nA superhero mom, first rate!\",\n",
       " 'prompt': PromptTemplate(input_variables=['image_desc'], output_parser=None, partial_variables={}, template='Generate a detailed prompt to generate an image based on the following social media post: {image_desc}', template_format='f-string', validate_template=True),\n",
       " 'image_prompt': \"Create an image of a mom lifting weights in the gym, with a determined expression on her face and a look of strength and power. She should be wearing workout clothes and have a towel draped over her shoulders. The background should be a gym with other people working out. The caption should read: #StrengthTrainingMom - A mom's job is never done, but with strength training she can handle any strife!\"}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "import os\n",
    "from langchain.utilities.dalle_image_generator import DallEAPIWrapper\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "def get_dalle_image(description, n=2, temperature=1, template=None, verbose=False):\n",
    "    llm = OpenAI(temperature=temperature, openai_organization=os.environ['openai_organization'])\n",
    "    description = description.strip()\n",
    "    if template:\n",
    "        template=template + ': {image_desc}'\n",
    "    else:\n",
    "        template=\"Generate a detailed prompt to generate an image based on the following social media post: {image_desc}\"\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"image_desc\"],\n",
    "        template=template,\n",
    "    )\n",
    "    print(f'Prompt template: {prompt.template}')\n",
    "    print(f'\\nInput: {description}')\n",
    "    chain = LLMChain(llm=llm, prompt=prompt, verbose=verbose)\n",
    "    image_prompt = chain.run(description).strip()\n",
    "    print(f'\\nImage prompt: {image_prompt}')\n",
    "    image_url = DallEAPIWrapper(n=n).run(image_prompt)\n",
    "    results = {\n",
    "        'image_url': image_url, \n",
    "        'description': description,\n",
    "        'prompt': prompt,\n",
    "        'image_prompt': image_prompt\n",
    "        }\n",
    "    return results\n",
    "\n",
    "iteration = 2.3\n",
    "\n",
    "descriptions[2] = poem\n",
    "results_dict[iteration] = get_dalle_image(descriptions[2], temperature=0)\n",
    "results_dict[iteration]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "474\n",
      "https://oaidalleapiprodscus.blob.core.windows.net/private/org-abUfYkwR7vFsTFp1p0qZ6YtJ/user-RXAiHh79huihhcA5ecHTcKIh/img-IWNebYx00yL0wCTfPAqrn8GT.png?st=2023-09-16T21%3A43%3A07Z&se=2023-09-16T23%3A43%3A07Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2023-09-15T23%3A07%3A57Z&ske=2023-09-16T23%3A07%3A57Z&sks=b&skv=2021-08-06&sig=SYoYsRVfzwppkfQMnY6tiSK/tG%2BxblKHy1/ixB/RUc4%3D\n"
     ]
    }
   ],
   "source": [
    "print(len(results_dict[iteration]['image_url']))\n",
    "print(results_dict[iteration]['image_url'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt template: Generate a detailed prompt to generate an image based on the following social media post: {image_desc}\n",
      "\n",
      "Input: # Strength Training Mom\n",
      "\n",
      "A mom's job is never done,\n",
      "From sunrise to setting sun,\n",
      "Her strength tested every day,\n",
      "Tough moments always come her way.\n",
      "\n",
      "But with strength training in her life,\n",
      "She can handle any strife,\n",
      "Lifting weights, building muscle,\n",
      "Makes her feel like she can hustle.\n",
      "\n",
      "Stronger body, stronger mind,\n",
      "More energy to unwind,\n",
      "Patient, loving, and kind,\n",
      "A better mom you'll find.\n",
      "\n",
      "So moms, don't be afraid,\n",
      "To lift weights and upgrade,\n",
      "Your strength will make you great,\n",
      "A superhero mom, first rate!\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mGenerate a detailed prompt to generate an image based on the following social media post: # Strength Training Mom\n",
      "\n",
      "A mom's job is never done,\n",
      "From sunrise to setting sun,\n",
      "Her strength tested every day,\n",
      "Tough moments always come her way.\n",
      "\n",
      "But with strength training in her life,\n",
      "She can handle any strife,\n",
      "Lifting weights, building muscle,\n",
      "Makes her feel like she can hustle.\n",
      "\n",
      "Stronger body, stronger mind,\n",
      "More energy to unwind,\n",
      "Patient, loving, and kind,\n",
      "A better mom you'll find.\n",
      "\n",
      "So moms, don't be afraid,\n",
      "To lift weights and upgrade,\n",
      "Your strength will make you great,\n",
      "A superhero mom, first rate!\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Image prompt: Create an image of a mom lifting weights in the gym, with a determined expression on her face and a look of strength and power. She should be wearing workout clothes and have a towel draped over her shoulders. The background should be a gym with other people working out. The caption should read: #StrengthTrainingMom - A mom's job is never done, but with strength training she can handle any strife!\n"
     ]
    },
    {
     "ename": "AuthenticationError",
     "evalue": "Incorrect API key provided: 2. You can find your API key at https://platform.openai.com/account/api-keys.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\silvh\\OneDrive\\lighthouse\\portfolio-projects\\AI-content\\notebooks\\2023-09-12 DALL-E experimentation.ipynb Cell 25\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/AI-content/notebooks/2023-09-12%20DALL-E%20experimentation.ipynb#X61sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m iteration \u001b[39m=\u001b[39m \u001b[39m2.31\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/AI-content/notebooks/2023-09-12%20DALL-E%20experimentation.ipynb#X61sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m descriptions[\u001b[39m2\u001b[39m] \u001b[39m=\u001b[39m poem\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/AI-content/notebooks/2023-09-12%20DALL-E%20experimentation.ipynb#X61sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m results_dict[iteration] \u001b[39m=\u001b[39m get_dalle_image(descriptions[\u001b[39m2\u001b[39m], temperature\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/AI-content/notebooks/2023-09-12%20DALL-E%20experimentation.ipynb#X61sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m results_dict[iteration]\n",
      "\u001b[1;32mc:\\Users\\silvh\\OneDrive\\lighthouse\\portfolio-projects\\AI-content\\notebooks\\2023-09-12 DALL-E experimentation.ipynb Cell 25\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/AI-content/notebooks/2023-09-12%20DALL-E%20experimentation.ipynb#X61sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m image_prompt \u001b[39m=\u001b[39m chain\u001b[39m.\u001b[39mrun(description)\u001b[39m.\u001b[39mstrip()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/AI-content/notebooks/2023-09-12%20DALL-E%20experimentation.ipynb#X61sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mImage prompt: \u001b[39m\u001b[39m{\u001b[39;00mimage_prompt\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/AI-content/notebooks/2023-09-12%20DALL-E%20experimentation.ipynb#X61sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m image_url \u001b[39m=\u001b[39m DallEAPIWrapper(openai_api_key\u001b[39m=\u001b[39mn)\u001b[39m.\u001b[39mrun(image_prompt)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/AI-content/notebooks/2023-09-12%20DALL-E%20experimentation.ipynb#X61sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m results \u001b[39m=\u001b[39m {\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/AI-content/notebooks/2023-09-12%20DALL-E%20experimentation.ipynb#X61sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mimage_url\u001b[39m\u001b[39m'\u001b[39m: image_url, \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/AI-content/notebooks/2023-09-12%20DALL-E%20experimentation.ipynb#X61sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mdescription\u001b[39m\u001b[39m'\u001b[39m: description,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/AI-content/notebooks/2023-09-12%20DALL-E%20experimentation.ipynb#X61sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mprompt\u001b[39m\u001b[39m'\u001b[39m: prompt,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/AI-content/notebooks/2023-09-12%20DALL-E%20experimentation.ipynb#X61sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mimage_prompt\u001b[39m\u001b[39m'\u001b[39m: image_prompt\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/AI-content/notebooks/2023-09-12%20DALL-E%20experimentation.ipynb#X61sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     }\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/AI-content/notebooks/2023-09-12%20DALL-E%20experimentation.ipynb#X61sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39mreturn\u001b[39;00m results\n",
      "File \u001b[1;32mc:\\Users\\silvh\\.conda\\envs\\projects\\Lib\\site-packages\\langchain\\utilities\\dalle_image_generator.py:54\u001b[0m, in \u001b[0;36mDallEAPIWrapper.run\u001b[1;34m(self, query)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun\u001b[39m(\u001b[39mself\u001b[39m, query: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[0;32m     53\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Run query through OpenAI and parse result.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 54\u001b[0m     image_url \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dalle_image_url(query)\n\u001b[0;32m     56\u001b[0m     \u001b[39mif\u001b[39;00m image_url \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m image_url \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m     57\u001b[0m         \u001b[39m# We don't want to return the assumption alone if answer is empty\u001b[39;00m\n\u001b[0;32m     58\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mNo image was generated\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\silvh\\.conda\\envs\\projects\\Lib\\site-packages\\langchain\\utilities\\dalle_image_generator.py:31\u001b[0m, in \u001b[0;36mDallEAPIWrapper._dalle_image_url\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_dalle_image_url\u001b[39m(\u001b[39mself\u001b[39m, prompt: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[0;32m     30\u001b[0m     params \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mprompt\u001b[39m\u001b[39m\"\u001b[39m: prompt, \u001b[39m\"\u001b[39m\u001b[39mn\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn, \u001b[39m\"\u001b[39m\u001b[39msize\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msize}\n\u001b[1;32m---> 31\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclient\u001b[39m.\u001b[39mcreate(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams)\n\u001b[0;32m     32\u001b[0m     \u001b[39mreturn\u001b[39;00m response[\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39murl\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\silvh\\.conda\\envs\\projects\\Lib\\site-packages\\openai\\api_resources\\image.py:36\u001b[0m, in \u001b[0;36mImage.create\u001b[1;34m(cls, api_key, api_base, api_type, api_version, organization, **params)\u001b[0m\n\u001b[0;32m     26\u001b[0m requestor \u001b[39m=\u001b[39m api_requestor\u001b[39m.\u001b[39mAPIRequestor(\n\u001b[0;32m     27\u001b[0m     api_key,\n\u001b[0;32m     28\u001b[0m     api_base\u001b[39m=\u001b[39mapi_base \u001b[39mor\u001b[39;00m openai\u001b[39m.\u001b[39mapi_base,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     31\u001b[0m     organization\u001b[39m=\u001b[39morganization,\n\u001b[0;32m     32\u001b[0m )\n\u001b[0;32m     34\u001b[0m _, api_version \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_get_api_type_and_version(api_type, api_version)\n\u001b[1;32m---> 36\u001b[0m response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39mrequest(\n\u001b[0;32m     37\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mpost\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_get_url(\u001b[39m\"\u001b[39m\u001b[39mgenerations\u001b[39m\u001b[39m\"\u001b[39m), params\n\u001b[0;32m     38\u001b[0m )\n\u001b[0;32m     40\u001b[0m \u001b[39mreturn\u001b[39;00m util\u001b[39m.\u001b[39mconvert_to_openai_object(\n\u001b[0;32m     41\u001b[0m     response, api_key, api_version, organization\n\u001b[0;32m     42\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\silvh\\.conda\\envs\\projects\\Lib\\site-packages\\openai\\api_requestor.py:226\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[1;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[0;32m    206\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    207\u001b[0m     method,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    214\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    215\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[0;32m    216\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[0;32m    217\u001b[0m         method\u001b[39m.\u001b[39mlower(),\n\u001b[0;32m    218\u001b[0m         url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    224\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[0;32m    225\u001b[0m     )\n\u001b[1;32m--> 226\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response(result, stream)\n\u001b[0;32m    227\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[1;32mc:\\Users\\silvh\\.conda\\envs\\projects\\Lib\\site-packages\\openai\\api_requestor.py:620\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[1;34m(self, result, stream)\u001b[0m\n\u001b[0;32m    612\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m    613\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[0;32m    614\u001b[0m             line, result\u001b[39m.\u001b[39mstatus_code, result\u001b[39m.\u001b[39mheaders, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    615\u001b[0m         )\n\u001b[0;32m    616\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m parse_stream(result\u001b[39m.\u001b[39miter_lines())\n\u001b[0;32m    617\u001b[0m     ), \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    618\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    619\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m--> 620\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[0;32m    621\u001b[0m             result\u001b[39m.\u001b[39mcontent\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[0;32m    622\u001b[0m             result\u001b[39m.\u001b[39mstatus_code,\n\u001b[0;32m    623\u001b[0m             result\u001b[39m.\u001b[39mheaders,\n\u001b[0;32m    624\u001b[0m             stream\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    625\u001b[0m         ),\n\u001b[0;32m    626\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    627\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\silvh\\.conda\\envs\\projects\\Lib\\site-packages\\openai\\api_requestor.py:683\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[1;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[0;32m    681\u001b[0m stream_error \u001b[39m=\u001b[39m stream \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m resp\u001b[39m.\u001b[39mdata\n\u001b[0;32m    682\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[1;32m--> 683\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[0;32m    684\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[0;32m    685\u001b[0m     )\n\u001b[0;32m    686\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "\u001b[1;31mAuthenticationError\u001b[0m: Incorrect API key provided: 2. You can find your API key at https://platform.openai.com/account/api-keys."
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "import os\n",
    "from langchain.utilities.dalle_image_generator import DallEAPIWrapper\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "def get_dalle_image(description, n=2, temperature=1, template=None, verbose=False):\n",
    "    llm = OpenAI(temperature=temperature, openai_organization=os.environ['openai_organization'])\n",
    "    description = description.strip()\n",
    "    if template:\n",
    "        template=template + ': {image_desc}'\n",
    "    else:\n",
    "        template=\"Generate a detailed prompt to generate an image based on the following social media post: {image_desc}\"\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"image_desc\"],\n",
    "        template=template,\n",
    "    )\n",
    "    print(f'Prompt template: {prompt.template}')\n",
    "    print(f'\\nInput: {description}')\n",
    "    chain = LLMChain(llm=llm, prompt=prompt, verbose=verbose)\n",
    "    image_prompt = chain.run(description).strip()\n",
    "    print(f'\\nImage prompt: {image_prompt}')\n",
    "    image_url = DallEAPIWrapper(openai_api_key=n).run(image_prompt)\n",
    "    results = {\n",
    "        'image_url': image_url, \n",
    "        'description': description,\n",
    "        'prompt': prompt,\n",
    "        'image_prompt': image_prompt\n",
    "        }\n",
    "    return results\n",
    "\n",
    "iteration = 2.31\n",
    "\n",
    "descriptions[2] = poem\n",
    "results_dict[iteration] = get_dalle_image(descriptions[2], temperature=0, verbose=True)\n",
    "results_dict[iteration]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "import os\n",
    "from langchain.utilities.dalle_image_generator import DallEAPIWrapper\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "def get_dalle_image(description, n=3, temperature=1, template=None, verbose=False):\n",
    "    llm = OpenAI(temperature=temperature, openai_organization=os.environ['openai_organization'])\n",
    "    description = description.strip()\n",
    "    if template:\n",
    "        template=template + ': {image_desc}'\n",
    "    else:\n",
    "        template=\"Generate a detailed prompt to generate an image based on the following social media post: {image_desc}\"\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"image_desc\"],\n",
    "        template=template,\n",
    "    )\n",
    "    print(f'Prompt template: {prompt.template}')\n",
    "    print(f'\\nInput: {description}')\n",
    "    chain = LLMChain(llm=llm, prompt=prompt, verbose=verbose)\n",
    "    image_prompt = chain.run(description).strip()\n",
    "    print(f'\\nImage prompt: {image_prompt}')\n",
    "    image_url = DallEAPIWrapper(n=n).run(image_prompt)\n",
    "    results = {\n",
    "        'image_url': image_url, \n",
    "        'description': description,\n",
    "        'prompt': prompt,\n",
    "        'image_prompt': image_prompt\n",
    "        }\n",
    "    return results\n",
    "\n",
    "iteration = 2.32\n",
    "\n",
    "descriptions[2] = poem\n",
    "results_dict[iteration] = get_dalle_image(descriptions[2], temperature=0, verbose=True)\n",
    "results_dict[iteration]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: Prompt:\n",
      "An image of a mom strength training with a determined yet peaceful look on her face. She is lifting weights and is wearing a comfortable and supportive workout outfit that she feels amazing in. Light is streaming through a window behind her, flooding the space with warmth and sunshine. The inspiring message from the social media post can be visually incorporated into the image – perhaps with a quote included in the background, or with the mom looking off into the distance, radiating determination and confidence.\n",
      "\n",
      "2: Create an image of a mom lifting weights in the gym, with a determined expression on her face and a look of strength and power. She should be wearing workout clothes and have a towel draped over her shoulders. The background should be a gym, with other people working out and weights scattered around. The caption should read: #StrengthTrainingMom - Showing the world that moms can be strong too!\n",
      "\n",
      "3: Create an image of a mom lifting weights in the gym, with a determined expression on her face and a look of strength and power. She should be wearing workout clothes and have a towel draped over her shoulders. The background should be a gym with other people working out. The caption should read: #StrengthTrainingMom - A mom's job is never done, but with strength training she can handle any strife!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def print_dict_values_for_key(results_dict, key, zero_indexed=False):\n",
    "    \"\"\"\n",
    "    Prints the values of a dictionary for a given key.\n",
    "\n",
    "    Parameters:\n",
    "    - results_dict (dict): Dictionary to print values for.\n",
    "    - key (str): Dictionary key to print values for.\n",
    "    - zero_indexed (bool): If True, prints the index of each value starting from 0. If False, prints the index starting from 1.\n",
    "        \"\"\"\n",
    "    for index, item in enumerate(results_dict):\n",
    "        print(f\"{index+1 if zero_indexed==False else index}: {results_dict[item].get(key, 'None').strip()}\", end='\\n\\n')\n",
    "\n",
    "print_dict_values_for_key(results_dict, 'image_prompt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make new posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2023-10-28 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt template: Generate a detailed prompt to generate an image based on the following social media post: {text}\n",
      "\n",
      "Input: Recently I made my first contribution to an open source project, LangChain. \n",
      "Looking at the source code, the fix was simple. However, adding my change to the project turned out to be more complicated than expected.\n",
      "I did not know how to test my updated code to ensure it worked as expected. The project gave instructions for testing the code, but I did not understand how to run them.\n",
      "Luckily, one of the project's maintainers simply accepted my change and made further revisions.\n",
      "\n",
      "I'd love to learn how to contribute code to open source Python packages. If you have a great resource on this or a great beginner-friendly project to contribute to, please let me know!\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mGenerate a detailed prompt to generate an image based on the following social media post: Recently I made my first contribution to an open source project, LangChain. \n",
      "Looking at the source code, the fix was simple. However, adding my change to the project turned out to be more complicated than expected.\n",
      "I did not know how to test my updated code to ensure it worked as expected. The project gave instructions for testing the code, but I did not understand how to run them.\n",
      "Luckily, one of the project's maintainers simply accepted my change and made further revisions.\n",
      "\n",
      "I'd love to learn how to contribute code to open source Python packages. If you have a great resource on this or a great beginner-friendly project to contribute to, please let me know!\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: You exceeded your current quota, please check your plan and billing details..\n",
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: You exceeded your current quota, please check your plan and billing details..\n",
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: You exceeded your current quota, please check your plan and billing details..\n",
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: You exceeded your current quota, please check your plan and billing details..\n",
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised RateLimitError: You exceeded your current quota, please check your plan and billing details..\n"
     ]
    },
    {
     "ename": "RateLimitError",
     "evalue": "You exceeded your current quota, please check your plan and billing details.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\silvh\\OneDrive\\lighthouse\\portfolio-projects\\AI-content\\notebooks\\2023-09-12 DALL-E experimentation.ipynb Cell 33\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/AI-content/notebooks/2023-09-12%20DALL-E%20experimentation.ipynb#X41sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m template \u001b[39m=\u001b[39m \u001b[39m\"\"\"\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/AI-content/notebooks/2023-09-12%20DALL-E%20experimentation.ipynb#X41sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m \u001b[39mYou create content on LinkedIn with the goal of building the writer\u001b[39m\u001b[39m'\u001b[39m\u001b[39ms professional brand as a data scientist who is continuously developing her skills. \u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/AI-content/notebooks/2023-09-12%20DALL-E%20experimentation.ipynb#X41sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m \u001b[39mThe writer is an Asian female who has her hair in a bun. Write a prompt to generate a cartoon image to accompany this LinkedIn post: \u001b[39m\u001b[39m{image_desc}\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/AI-content/notebooks/2023-09-12%20DALL-E%20experimentation.ipynb#X41sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m \u001b[39m\"\"\"\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/AI-content/notebooks/2023-09-12%20DALL-E%20experimentation.ipynb#X41sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m iteration \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/AI-content/notebooks/2023-09-12%20DALL-E%20experimentation.ipynb#X41sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m results_dict[iteration] \u001b[39m=\u001b[39m get_dalle_image(post, temperature\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;32mc:\\Users\\silvh\\OneDrive\\lighthouse\\portfolio-projects\\AI-content\\notebooks\\2023-09-12 DALL-E experimentation.ipynb Cell 33\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/AI-content/notebooks/2023-09-12%20DALL-E%20experimentation.ipynb#X41sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mInput: \u001b[39m\u001b[39m{\u001b[39;00mtext\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/AI-content/notebooks/2023-09-12%20DALL-E%20experimentation.ipynb#X41sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m chain \u001b[39m=\u001b[39m LLMChain(llm\u001b[39m=\u001b[39mllm, prompt\u001b[39m=\u001b[39mprompt, verbose\u001b[39m=\u001b[39mverbose)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/AI-content/notebooks/2023-09-12%20DALL-E%20experimentation.ipynb#X41sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m image_prompt \u001b[39m=\u001b[39m chain\u001b[39m.\u001b[39mrun(text)\u001b[39m.\u001b[39mstrip()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/AI-content/notebooks/2023-09-12%20DALL-E%20experimentation.ipynb#X41sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mImage prompt: \u001b[39m\u001b[39m{\u001b[39;00mimage_prompt\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/AI-content/notebooks/2023-09-12%20DALL-E%20experimentation.ipynb#X41sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m image_url \u001b[39m=\u001b[39m DallEAPIWrapper(n\u001b[39m=\u001b[39mn)\u001b[39m.\u001b[39mrun(image_prompt)\n",
      "File \u001b[1;32mc:\\Users\\silvh\\.conda\\envs\\projects\\Lib\\site-packages\\langchain\\chains\\base.py:487\u001b[0m, in \u001b[0;36mChain.run\u001b[1;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[0m\n\u001b[0;32m    485\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    486\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m`run` supports only one positional argument.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 487\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m(args[\u001b[39m0\u001b[39m], callbacks\u001b[39m=\u001b[39mcallbacks, tags\u001b[39m=\u001b[39mtags, metadata\u001b[39m=\u001b[39mmetadata)[\n\u001b[0;32m    488\u001b[0m         _output_key\n\u001b[0;32m    489\u001b[0m     ]\n\u001b[0;32m    491\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m args:\n\u001b[0;32m    492\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m(kwargs, callbacks\u001b[39m=\u001b[39mcallbacks, tags\u001b[39m=\u001b[39mtags, metadata\u001b[39m=\u001b[39mmetadata)[\n\u001b[0;32m    493\u001b[0m         _output_key\n\u001b[0;32m    494\u001b[0m     ]\n",
      "File \u001b[1;32mc:\\Users\\silvh\\.conda\\envs\\projects\\Lib\\site-packages\\langchain\\chains\\base.py:292\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[0;32m    290\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    291\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n\u001b[1;32m--> 292\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[0;32m    293\u001b[0m run_manager\u001b[39m.\u001b[39mon_chain_end(outputs)\n\u001b[0;32m    294\u001b[0m final_outputs: Dict[\u001b[39mstr\u001b[39m, Any] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_outputs(\n\u001b[0;32m    295\u001b[0m     inputs, outputs, return_only_outputs\n\u001b[0;32m    296\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\silvh\\.conda\\envs\\projects\\Lib\\site-packages\\langchain\\chains\\base.py:286\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[0;32m    279\u001b[0m run_manager \u001b[39m=\u001b[39m callback_manager\u001b[39m.\u001b[39mon_chain_start(\n\u001b[0;32m    280\u001b[0m     dumpd(\u001b[39mself\u001b[39m),\n\u001b[0;32m    281\u001b[0m     inputs,\n\u001b[0;32m    282\u001b[0m     name\u001b[39m=\u001b[39mrun_name,\n\u001b[0;32m    283\u001b[0m )\n\u001b[0;32m    284\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    285\u001b[0m     outputs \u001b[39m=\u001b[39m (\n\u001b[1;32m--> 286\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(inputs, run_manager\u001b[39m=\u001b[39mrun_manager)\n\u001b[0;32m    287\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    288\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(inputs)\n\u001b[0;32m    289\u001b[0m     )\n\u001b[0;32m    290\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    291\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[1;32mc:\\Users\\silvh\\.conda\\envs\\projects\\Lib\\site-packages\\langchain\\chains\\llm.py:91\u001b[0m, in \u001b[0;36mLLMChain._call\u001b[1;34m(self, inputs, run_manager)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call\u001b[39m(\n\u001b[0;32m     87\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m     88\u001b[0m     inputs: Dict[\u001b[39mstr\u001b[39m, Any],\n\u001b[0;32m     89\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m     90\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Dict[\u001b[39mstr\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[1;32m---> 91\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgenerate([inputs], run_manager\u001b[39m=\u001b[39mrun_manager)\n\u001b[0;32m     92\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcreate_outputs(response)[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\silvh\\.conda\\envs\\projects\\Lib\\site-packages\\langchain\\chains\\llm.py:101\u001b[0m, in \u001b[0;36mLLMChain.generate\u001b[1;34m(self, input_list, run_manager)\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Generate LLM result from inputs.\"\"\"\u001b[39;00m\n\u001b[0;32m    100\u001b[0m prompts, stop \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_prompts(input_list, run_manager\u001b[39m=\u001b[39mrun_manager)\n\u001b[1;32m--> 101\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mllm\u001b[39m.\u001b[39mgenerate_prompt(\n\u001b[0;32m    102\u001b[0m     prompts,\n\u001b[0;32m    103\u001b[0m     stop,\n\u001b[0;32m    104\u001b[0m     callbacks\u001b[39m=\u001b[39mrun_manager\u001b[39m.\u001b[39mget_child() \u001b[39mif\u001b[39;00m run_manager \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    105\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mllm_kwargs,\n\u001b[0;32m    106\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\silvh\\.conda\\envs\\projects\\Lib\\site-packages\\langchain\\llms\\base.py:486\u001b[0m, in \u001b[0;36mBaseLLM.generate_prompt\u001b[1;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    478\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerate_prompt\u001b[39m(\n\u001b[0;32m    479\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    480\u001b[0m     prompts: List[PromptValue],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    483\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[0;32m    484\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m LLMResult:\n\u001b[0;32m    485\u001b[0m     prompt_strings \u001b[39m=\u001b[39m [p\u001b[39m.\u001b[39mto_string() \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m prompts]\n\u001b[1;32m--> 486\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgenerate(prompt_strings, stop\u001b[39m=\u001b[39mstop, callbacks\u001b[39m=\u001b[39mcallbacks, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\silvh\\.conda\\envs\\projects\\Lib\\site-packages\\langchain\\llms\\base.py:621\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[1;34m(self, prompts, stop, callbacks, tags, metadata, **kwargs)\u001b[0m\n\u001b[0;32m    612\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    613\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mAsked to cache, but no cache found at `langchain.cache`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    614\u001b[0m         )\n\u001b[0;32m    615\u001b[0m     run_managers \u001b[39m=\u001b[39m [\n\u001b[0;32m    616\u001b[0m         callback_manager\u001b[39m.\u001b[39mon_llm_start(\n\u001b[0;32m    617\u001b[0m             dumpd(\u001b[39mself\u001b[39m), [prompt], invocation_params\u001b[39m=\u001b[39mparams, options\u001b[39m=\u001b[39moptions\n\u001b[0;32m    618\u001b[0m         )[\u001b[39m0\u001b[39m]\n\u001b[0;32m    619\u001b[0m         \u001b[39mfor\u001b[39;00m callback_manager, prompt \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(callback_managers, prompts)\n\u001b[0;32m    620\u001b[0m     ]\n\u001b[1;32m--> 621\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generate_helper(\n\u001b[0;32m    622\u001b[0m         prompts, stop, run_managers, \u001b[39mbool\u001b[39m(new_arg_supported), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[0;32m    623\u001b[0m     )\n\u001b[0;32m    624\u001b[0m     \u001b[39mreturn\u001b[39;00m output\n\u001b[0;32m    625\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(missing_prompts) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\silvh\\.conda\\envs\\projects\\Lib\\site-packages\\langchain\\llms\\base.py:523\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[1;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[0;32m    521\u001b[0m     \u001b[39mfor\u001b[39;00m run_manager \u001b[39min\u001b[39;00m run_managers:\n\u001b[0;32m    522\u001b[0m         run_manager\u001b[39m.\u001b[39mon_llm_error(e)\n\u001b[1;32m--> 523\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[0;32m    524\u001b[0m flattened_outputs \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39mflatten()\n\u001b[0;32m    525\u001b[0m \u001b[39mfor\u001b[39;00m manager, flattened_output \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(run_managers, flattened_outputs):\n",
      "File \u001b[1;32mc:\\Users\\silvh\\.conda\\envs\\projects\\Lib\\site-packages\\langchain\\llms\\base.py:510\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[1;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[0;32m    500\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_generate_helper\u001b[39m(\n\u001b[0;32m    501\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    502\u001b[0m     prompts: List[\u001b[39mstr\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    506\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[0;32m    507\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m LLMResult:\n\u001b[0;32m    508\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    509\u001b[0m         output \u001b[39m=\u001b[39m (\n\u001b[1;32m--> 510\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generate(\n\u001b[0;32m    511\u001b[0m                 prompts,\n\u001b[0;32m    512\u001b[0m                 stop\u001b[39m=\u001b[39mstop,\n\u001b[0;32m    513\u001b[0m                 \u001b[39m# TODO: support multiple run managers\u001b[39;00m\n\u001b[0;32m    514\u001b[0m                 run_manager\u001b[39m=\u001b[39mrun_managers[\u001b[39m0\u001b[39m] \u001b[39mif\u001b[39;00m run_managers \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    515\u001b[0m                 \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m    516\u001b[0m             )\n\u001b[0;32m    517\u001b[0m             \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    518\u001b[0m             \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generate(prompts, stop\u001b[39m=\u001b[39mstop)\n\u001b[0;32m    519\u001b[0m         )\n\u001b[0;32m    520\u001b[0m     \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    521\u001b[0m         \u001b[39mfor\u001b[39;00m run_manager \u001b[39min\u001b[39;00m run_managers:\n",
      "File \u001b[1;32mc:\\Users\\silvh\\.conda\\envs\\projects\\Lib\\site-packages\\langchain\\llms\\openai.py:385\u001b[0m, in \u001b[0;36mBaseOpenAI._generate\u001b[1;34m(self, prompts, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    373\u001b[0m     choices\u001b[39m.\u001b[39mappend(\n\u001b[0;32m    374\u001b[0m         {\n\u001b[0;32m    375\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m: generation\u001b[39m.\u001b[39mtext,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    382\u001b[0m         }\n\u001b[0;32m    383\u001b[0m     )\n\u001b[0;32m    384\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 385\u001b[0m     response \u001b[39m=\u001b[39m completion_with_retry(\n\u001b[0;32m    386\u001b[0m         \u001b[39mself\u001b[39m, prompt\u001b[39m=\u001b[39m_prompts, run_manager\u001b[39m=\u001b[39mrun_manager, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[0;32m    387\u001b[0m     )\n\u001b[0;32m    388\u001b[0m     choices\u001b[39m.\u001b[39mextend(response[\u001b[39m\"\u001b[39m\u001b[39mchoices\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m    389\u001b[0m     update_token_usage(_keys, response, token_usage)\n",
      "File \u001b[1;32mc:\\Users\\silvh\\.conda\\envs\\projects\\Lib\\site-packages\\langchain\\llms\\openai.py:115\u001b[0m, in \u001b[0;36mcompletion_with_retry\u001b[1;34m(llm, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[39m@retry_decorator\u001b[39m\n\u001b[0;32m    112\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_completion_with_retry\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m    113\u001b[0m     \u001b[39mreturn\u001b[39;00m llm\u001b[39m.\u001b[39mclient\u001b[39m.\u001b[39mcreate(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 115\u001b[0m \u001b[39mreturn\u001b[39;00m _completion_with_retry(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\silvh\\.conda\\envs\\projects\\Lib\\site-packages\\tenacity\\__init__.py:289\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(f)\n\u001b[0;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_f\u001b[39m(\u001b[39m*\u001b[39margs: t\u001b[39m.\u001b[39mAny, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw: t\u001b[39m.\u001b[39mAny) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m t\u001b[39m.\u001b[39mAny:\n\u001b[1;32m--> 289\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m(f, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw)\n",
      "File \u001b[1;32mc:\\Users\\silvh\\.conda\\envs\\projects\\Lib\\site-packages\\tenacity\\__init__.py:379\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    377\u001b[0m retry_state \u001b[39m=\u001b[39m RetryCallState(retry_object\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, fn\u001b[39m=\u001b[39mfn, args\u001b[39m=\u001b[39margs, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[0;32m    378\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m--> 379\u001b[0m     do \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39miter(retry_state\u001b[39m=\u001b[39mretry_state)\n\u001b[0;32m    380\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoAttempt):\n\u001b[0;32m    381\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\silvh\\.conda\\envs\\projects\\Lib\\site-packages\\tenacity\\__init__.py:325\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[1;34m(self, retry_state)\u001b[0m\n\u001b[0;32m    323\u001b[0m     retry_exc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mretry_error_cls(fut)\n\u001b[0;32m    324\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreraise:\n\u001b[1;32m--> 325\u001b[0m         \u001b[39mraise\u001b[39;00m retry_exc\u001b[39m.\u001b[39mreraise()\n\u001b[0;32m    326\u001b[0m     \u001b[39mraise\u001b[39;00m retry_exc \u001b[39mfrom\u001b[39;00m \u001b[39mfut\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexception\u001b[39;00m()\n\u001b[0;32m    328\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwait:\n",
      "File \u001b[1;32mc:\\Users\\silvh\\.conda\\envs\\projects\\Lib\\site-packages\\tenacity\\__init__.py:158\u001b[0m, in \u001b[0;36mRetryError.reraise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreraise\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m t\u001b[39m.\u001b[39mNoReturn:\n\u001b[0;32m    157\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlast_attempt\u001b[39m.\u001b[39mfailed:\n\u001b[1;32m--> 158\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlast_attempt\u001b[39m.\u001b[39mresult()\n\u001b[0;32m    159\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\silvh\\.conda\\envs\\projects\\Lib\\concurrent\\futures\\_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    448\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[1;32m--> 449\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_result()\n\u001b[0;32m    451\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_condition\u001b[39m.\u001b[39mwait(timeout)\n\u001b[0;32m    453\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[1;32mc:\\Users\\silvh\\.conda\\envs\\projects\\Lib\\concurrent\\futures\\_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[0;32m    400\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 401\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[0;32m    402\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    403\u001b[0m         \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    404\u001b[0m         \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\silvh\\.conda\\envs\\projects\\Lib\\site-packages\\tenacity\\__init__.py:382\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoAttempt):\n\u001b[0;32m    381\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 382\u001b[0m         result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    383\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m:  \u001b[39m# noqa: B902\u001b[39;00m\n\u001b[0;32m    384\u001b[0m         retry_state\u001b[39m.\u001b[39mset_exception(sys\u001b[39m.\u001b[39mexc_info())  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\silvh\\.conda\\envs\\projects\\Lib\\site-packages\\langchain\\llms\\openai.py:113\u001b[0m, in \u001b[0;36mcompletion_with_retry.<locals>._completion_with_retry\u001b[1;34m(**kwargs)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[39m@retry_decorator\u001b[39m\n\u001b[0;32m    112\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_completion_with_retry\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m--> 113\u001b[0m     \u001b[39mreturn\u001b[39;00m llm\u001b[39m.\u001b[39mclient\u001b[39m.\u001b[39mcreate(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\silvh\\.conda\\envs\\projects\\Lib\\site-packages\\openai\\api_resources\\completion.py:25\u001b[0m, in \u001b[0;36mCompletion.create\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 25\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mcreate(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     26\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n",
      "File \u001b[1;32mc:\\Users\\silvh\\.conda\\envs\\projects\\Lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[1;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[0;32m    129\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[0;32m    137\u001b[0m ):\n\u001b[0;32m    138\u001b[0m     (\n\u001b[0;32m    139\u001b[0m         deployment_id,\n\u001b[0;32m    140\u001b[0m         engine,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[0;32m    151\u001b[0m     )\n\u001b[1;32m--> 153\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39mrequest(\n\u001b[0;32m    154\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mpost\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    155\u001b[0m         url,\n\u001b[0;32m    156\u001b[0m         params\u001b[39m=\u001b[39mparams,\n\u001b[0;32m    157\u001b[0m         headers\u001b[39m=\u001b[39mheaders,\n\u001b[0;32m    158\u001b[0m         stream\u001b[39m=\u001b[39mstream,\n\u001b[0;32m    159\u001b[0m         request_id\u001b[39m=\u001b[39mrequest_id,\n\u001b[0;32m    160\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[0;32m    161\u001b[0m     )\n\u001b[0;32m    163\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[0;32m    164\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[0;32m    165\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[1;32mc:\\Users\\silvh\\.conda\\envs\\projects\\Lib\\site-packages\\openai\\api_requestor.py:226\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[1;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[0;32m    206\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    207\u001b[0m     method,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    214\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    215\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[0;32m    216\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[0;32m    217\u001b[0m         method\u001b[39m.\u001b[39mlower(),\n\u001b[0;32m    218\u001b[0m         url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    224\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[0;32m    225\u001b[0m     )\n\u001b[1;32m--> 226\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response(result, stream)\n\u001b[0;32m    227\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[1;32mc:\\Users\\silvh\\.conda\\envs\\projects\\Lib\\site-packages\\openai\\api_requestor.py:620\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[1;34m(self, result, stream)\u001b[0m\n\u001b[0;32m    612\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m    613\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[0;32m    614\u001b[0m             line, result\u001b[39m.\u001b[39mstatus_code, result\u001b[39m.\u001b[39mheaders, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    615\u001b[0m         )\n\u001b[0;32m    616\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m parse_stream(result\u001b[39m.\u001b[39miter_lines())\n\u001b[0;32m    617\u001b[0m     ), \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    618\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    619\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m--> 620\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[0;32m    621\u001b[0m             result\u001b[39m.\u001b[39mcontent\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[0;32m    622\u001b[0m             result\u001b[39m.\u001b[39mstatus_code,\n\u001b[0;32m    623\u001b[0m             result\u001b[39m.\u001b[39mheaders,\n\u001b[0;32m    624\u001b[0m             stream\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    625\u001b[0m         ),\n\u001b[0;32m    626\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    627\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\silvh\\.conda\\envs\\projects\\Lib\\site-packages\\openai\\api_requestor.py:683\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[1;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[0;32m    681\u001b[0m stream_error \u001b[39m=\u001b[39m stream \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m resp\u001b[39m.\u001b[39mdata\n\u001b[0;32m    682\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[1;32m--> 683\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[0;32m    684\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[0;32m    685\u001b[0m     )\n\u001b[0;32m    686\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "\u001b[1;31mRateLimitError\u001b[0m: You exceeded your current quota, please check your plan and billing details."
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "import os\n",
    "from langchain.utilities.dalle_image_generator import DallEAPIWrapper\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "def get_dalle_image(text, n=3, temperature=1, template=None, verbose=False):\n",
    "    llm = OpenAI(temperature=temperature, openai_organization=os.environ['openai_organization'])\n",
    "    text = text.strip()\n",
    "    if template:\n",
    "        template=template + ': {text}'\n",
    "    else:\n",
    "        template=\"Generate a detailed prompt to generate an image based on the following social media post: {text}\"\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"text\"],\n",
    "        template=template,\n",
    "    )\n",
    "    print(f'Prompt template: {prompt.template}')\n",
    "    print(f'\\nInput: {text}')\n",
    "    chain = LLMChain(llm=llm, prompt=prompt, verbose=verbose)\n",
    "    image_prompt = chain.run(text).strip()\n",
    "    print(f'\\nImage prompt: {image_prompt}')\n",
    "    image_url = DallEAPIWrapper(n=n).run(image_prompt)\n",
    "    results = {\n",
    "        'image_url': image_url, \n",
    "        'description': text,\n",
    "        'prompt': prompt,\n",
    "        'image_prompt': image_prompt\n",
    "        }\n",
    "    return results\n",
    "\n",
    "post = \"\"\"\n",
    "Recently I made my first contribution to an open source project, LangChain. \n",
    "Looking at the source code, the fix was simple. However, adding my change to the project turned out to be more complicated than expected.\n",
    "I did not know how to test my updated code to ensure it worked as expected. The project gave instructions for testing the code, but I did not understand how to run them.\n",
    "Luckily, one of the project's maintainers simply accepted my change and made further revisions.\n",
    "\n",
    "I'd love to learn how to contribute code to open source Python packages. If you have a great resource on this or a great beginner-friendly project to contribute to, please let me know!\n",
    "\"\"\"\n",
    "\n",
    "template = \"\"\"\n",
    "You create content on LinkedIn with the goal of building the writer's professional brand as a data scientist who is continuously developing her skills. \n",
    "The writer is an Asian female who has her hair in a bun. Write a prompt to generate a cartoon image to accompany this LinkedIn post: {image_desc}\n",
    "\"\"\"\n",
    "iteration = 1\n",
    "results_dict[iteration] = get_dalle_image(post, temperature=0, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## iteration 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt template: Generate a detailed prompt to generate an image based on the following social media post: {text}\n",
      "\n",
      "Input: Recently I made my first contribution to an open source project, LangChain. \n",
      "Looking at the source code, the fix was simple. However, adding my change to the project turned out to be more complicated than expected.\n",
      "I did not know how to test my updated code to ensure it worked as expected. The project gave instructions for testing the code, but I did not understand how to run them.\n",
      "Luckily, one of the project's maintainers simply accepted my change and made further revisions.\n",
      "\n",
      "I'd love to learn how to contribute code to open source Python packages. If you have a great resource on this or a great beginner-friendly project to contribute to, please let me know!\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mGenerate a detailed prompt to generate an image based on the following social media post: Recently I made my first contribution to an open source project, LangChain. \n",
      "Looking at the source code, the fix was simple. However, adding my change to the project turned out to be more complicated than expected.\n",
      "I did not know how to test my updated code to ensure it worked as expected. The project gave instructions for testing the code, but I did not understand how to run them.\n",
      "Luckily, one of the project's maintainers simply accepted my change and made further revisions.\n",
      "\n",
      "I'd love to learn how to contribute code to open source Python packages. If you have a great resource on this or a great beginner-friendly project to contribute to, please let me know!\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Image prompt: Create an image that captures the feeling of accomplishment and relief after successfully making a contribution to an open source project. Show a person looking at a computer screen with a smile of satisfaction, surrounded by a bright, vibrant background of colors and shapes to represent the joy of success.\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "import os\n",
    "from langchain.utilities.dalle_image_generator import DallEAPIWrapper\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "def get_dalle_image(text, n=3, temperature=1, template=None, verbose=False, max_retries=1, max_tokens=900):\n",
    "    llm = OpenAI(\n",
    "        temperature=temperature, openai_organization=os.environ['openai_organization'],\n",
    "        max_retries=max_retries, max_tokens=max_tokens\n",
    "        )\n",
    "    text = text.strip()\n",
    "    if template:\n",
    "        template=template + ': {text}'\n",
    "    else:\n",
    "        template=\"Generate a detailed prompt to generate an image based on the following social media post: {text}\"\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"text\"],\n",
    "        template=template,\n",
    "    )\n",
    "    print(f'Prompt template: {prompt.template}')\n",
    "    print(f'\\nInput: {text}')\n",
    "    chain = LLMChain(llm=llm, prompt=prompt, verbose=verbose)\n",
    "    image_prompt = chain.run(text).strip()\n",
    "    print(f'\\nImage prompt: {image_prompt}')\n",
    "    image_url = DallEAPIWrapper(n=n).run(image_prompt)\n",
    "    results = {\n",
    "        'image_url': image_url, \n",
    "        'description': text,\n",
    "        'prompt': prompt,\n",
    "        'image_prompt': image_prompt\n",
    "        }\n",
    "    return results\n",
    "\n",
    "post = \"\"\"\n",
    "Recently I made my first contribution to an open source project, LangChain. \n",
    "Looking at the source code, the fix was simple. However, adding my change to the project turned out to be more complicated than expected.\n",
    "I did not know how to test my updated code to ensure it worked as expected. The project gave instructions for testing the code, but I did not understand how to run them.\n",
    "Luckily, one of the project's maintainers simply accepted my change and made further revisions.\n",
    "\n",
    "I'd love to learn how to contribute code to open source Python packages. If you have a great resource on this or a great beginner-friendly project to contribute to, please let me know!\n",
    "\"\"\"\n",
    "\n",
    "template = \"\"\"\n",
    "You create content on LinkedIn with the goal of building the writer's professional brand as a data scientist who is continuously developing her skills. \n",
    "The writer is an Asian female who has her hair in a bun. Write a prompt to generate a cartoon image to accompany this LinkedIn post: {image_desc}\n",
    "\"\"\"\n",
    "iteration = 1\n",
    "results_dict[iteration] = get_dalle_image(post, temperature=0, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image_url': 'https://oaidalleapiprodscus.blob.core.windows.net/private/org-abUfYkwR7vFsTFp1p0qZ6YtJ/user-RXAiHh79huihhcA5ecHTcKIh/img-d1NAkQ84IBr1mDQaK0cK6xbF.png?st=2023-10-28T23%3A05%3A33Z&se=2023-10-29T01%3A05%3A33Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2023-10-28T23%3A17%3A40Z&ske=2023-10-29T23%3A17%3A40Z&sks=b&skv=2021-08-06&sig=UfAljfbug5bE4%2BlFv/%2BYy2XPrfUGE206woxJRNlQ/k4%3D',\n",
       " 'description': \"Recently I made my first contribution to an open source project, LangChain. \\nLooking at the source code, the fix was simple. However, adding my change to the project turned out to be more complicated than expected.\\nI did not know how to test my updated code to ensure it worked as expected. The project gave instructions for testing the code, but I did not understand how to run them.\\nLuckily, one of the project's maintainers simply accepted my change and made further revisions.\\n\\nI'd love to learn how to contribute code to open source Python packages. If you have a great resource on this or a great beginner-friendly project to contribute to, please let me know!\",\n",
       " 'prompt': PromptTemplate(input_variables=['text'], output_parser=None, partial_variables={}, template='Generate a detailed prompt to generate an image based on the following social media post: {text}', template_format='f-string', validate_template=True),\n",
       " 'image_prompt': 'Create an image that captures the feeling of accomplishment and relief after successfully making a contribution to an open source project. Show a person looking at a computer screen with a smile of satisfaction, surrounded by a bright, vibrant background of colors and shapes to represent the joy of success.'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_dict[iteration]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recently I made my first contribution to an open source project, LangChain. \n",
      "Looking at the source code, the fix was simple. However, adding my change to the project turned out to be more complicated than expected.\n",
      "I did not know how to test my updated code to ensure it worked as expected. The project gave instructions for testing the code, but I did not understand how to run them.\n",
      "Luckily, one of the project's maintainers simply accepted my change and made further revisions.\n",
      "\n",
      "I'd love to learn how to contribute code to open source Python packages. If you have a great resource on this or a great beginner-friendly project to contribute to, please let me know!\n",
      "\n",
      "\n",
      "PS: This image was generated by DALL-E. I asked OpenAI to generate the DALL-E prompt based on the text of the above post, and this was the result: \"Prompt for Cartoon Image: An Asian female data scientist with her hair in a bun, looking determined and focused as she works on her laptop, with a caption that reads: \"Taking the first step towards becoming a data scientist!\"\".\n",
      "\n",
      "PPS: If you really want to know, the prompt template I used to generate the DALL-E prompt was as follows: \"You create content on LinkedIn with the goal of building the writer's professional brand as a data scientist who is continuously developing her skills. \n",
      "The writer is an Asian female who has her hair in a bun. Write a prompt to generate a cartoon image to accompany this LinkedIn post: {text}\"\n",
      "\n",
      "\n",
      "#datascience #llm \n"
     ]
    }
   ],
   "source": [
    "def print_dict_values_for_key(results_dict, key, zero_indexed=False):\n",
    "    \"\"\"\n",
    "    Prints the values of a dictionary for a given key.\n",
    "\n",
    "    Parameters:\n",
    "    - results_dict (dict): Dictionary to print values for.\n",
    "    - key (str): Dictionary key to print values for.\n",
    "    - zero_indexed (bool): If True, prints the index of each value starting from 0. If False, prints the index starting from 1.\n",
    "        \"\"\"\n",
    "    for index, item in enumerate(results_dict):\n",
    "        print(f\"{index+1 if zero_indexed==False else index}: {results_dict[item].get(key, 'None').strip()}\", end='\\n\\n')\n",
    "\n",
    "def create_linkedin_post(results_dict, iteration, hashtags=['datascience', 'llm']):\n",
    "    print(results_dict[iteration]['description'])\n",
    "    print(f'\\n\\nPS: This image was generated by DALL-E. I asked OpenAI to generate the DALL-E prompt based on the text of the above post, and this was the result: \"{results_dict[iteration][\"image_prompt\"].strip()}\".')\n",
    "    print(f'\\nPPS: If you really want to know, the prompt template I used to generate the DALL-E prompt was as follows: \"{results_dict[iteration][\"prompt\"].template[:-8].strip()}\"')\n",
    "    print(f'\\n\\n{\"\".join([f\"#{tag} \" for tag in hashtags])}')\n",
    "\n",
    "create_linkedin_post(results_dict, iteration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iteration 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt template: \n",
      "You create content on LinkedIn with the goal of building the writer's professional brand as a data scientist who is continuously developing her skills. \n",
      "The writer is an Asian female who has her hair in a bun. Write a prompt to generate a cartoon image to accompany this LinkedIn post: {text}\n",
      ": {text}\n",
      "\n",
      "Input: Recently I made my first contribution to an open source project, LangChain. \n",
      "Looking at the source code, the fix was simple. However, adding my change to the project turned out to be more complicated than expected.\n",
      "I did not know how to test my updated code to ensure it worked as expected. The project gave instructions for testing the code, but I did not understand how to run them.\n",
      "Luckily, one of the project's maintainers simply accepted my change and made further revisions.\n",
      "\n",
      "I'd love to learn how to contribute code to open source Python packages. If you have a great resource on this or a great beginner-friendly project to contribute to, please let me know!\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "You create content on LinkedIn with the goal of building the writer's professional brand as a data scientist who is continuously developing her skills. \n",
      "The writer is an Asian female who has her hair in a bun. Write a prompt to generate a cartoon image to accompany this LinkedIn post: Recently I made my first contribution to an open source project, LangChain. \n",
      "Looking at the source code, the fix was simple. However, adding my change to the project turned out to be more complicated than expected.\n",
      "I did not know how to test my updated code to ensure it worked as expected. The project gave instructions for testing the code, but I did not understand how to run them.\n",
      "Luckily, one of the project's maintainers simply accepted my change and made further revisions.\n",
      "\n",
      "I'd love to learn how to contribute code to open source Python packages. If you have a great resource on this or a great beginner-friendly project to contribute to, please let me know!\n",
      ": Recently I made my first contribution to an open source project, LangChain. \n",
      "Looking at the source code, the fix was simple. However, adding my change to the project turned out to be more complicated than expected.\n",
      "I did not know how to test my updated code to ensure it worked as expected. The project gave instructions for testing the code, but I did not understand how to run them.\n",
      "Luckily, one of the project's maintainers simply accepted my change and made further revisions.\n",
      "\n",
      "I'd love to learn how to contribute code to open source Python packages. If you have a great resource on this or a great beginner-friendly project to contribute to, please let me know!\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Image prompt: Prompt for Cartoon Image: An Asian female data scientist with her hair in a bun, looking determined and focused as she works on her laptop, with a caption that reads: \"Taking the first step towards becoming a data scientist!\"\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "import os\n",
    "from langchain.utilities.dalle_image_generator import DallEAPIWrapper\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "def get_dalle_image(text, n=3, temperature=1, template=None, verbose=False, max_retries=1, max_tokens=900):\n",
    "    llm = OpenAI(\n",
    "        temperature=temperature, openai_organization=os.environ['openai_organization'],\n",
    "        max_retries=max_retries, max_tokens=max_tokens\n",
    "        )\n",
    "    text = text.strip()\n",
    "    if template:\n",
    "        template=template + ': {text}'\n",
    "    else:\n",
    "        template=\"Generate a detailed prompt to generate an image based on the following social media post: {text}\"\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"text\"],\n",
    "        template=template,\n",
    "    )\n",
    "    print(f'Prompt template: {prompt.template}')\n",
    "    print(f'\\nInput: {text}')\n",
    "    chain = LLMChain(llm=llm, prompt=prompt, verbose=verbose)\n",
    "    image_prompt = chain.run(text).strip()\n",
    "    print(f'\\nImage prompt: {image_prompt}')\n",
    "    image_url = DallEAPIWrapper(n=n).run(image_prompt)\n",
    "    results = {\n",
    "        'image_url': image_url, \n",
    "        'description': text,\n",
    "        'prompt': prompt,\n",
    "        'image_prompt': image_prompt\n",
    "        }\n",
    "    return results\n",
    "\n",
    "post = \"\"\"\n",
    "Recently I made my first contribution to an open source project, LangChain. \n",
    "Looking at the source code, the fix was simple. However, adding my change to the project turned out to be more complicated than expected.\n",
    "I did not know how to test my updated code to ensure it worked as expected. The project gave instructions for testing the code, but I did not understand how to run them.\n",
    "Luckily, one of the project's maintainers simply accepted my change and made further revisions.\n",
    "\n",
    "I'd love to learn how to contribute code to open source Python packages. If you have a great resource on this or a great beginner-friendly project to contribute to, please let me know!\n",
    "\"\"\"\n",
    "\n",
    "template = \"\"\"\n",
    "You create content on LinkedIn with the goal of building the writer's professional brand as a data scientist who is continuously developing her skills. \n",
    "The writer is an Asian female who has her hair in a bun. Write a prompt to generate a cartoon image to accompany this LinkedIn post: {text}\n",
    "\"\"\"\n",
    "\n",
    "iteration = 2\n",
    "results_dict[iteration] = get_dalle_image(post, template=template, temperature=0, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image_url': 'https://oaidalleapiprodscus.blob.core.windows.net/private/org-abUfYkwR7vFsTFp1p0qZ6YtJ/user-RXAiHh79huihhcA5ecHTcKIh/img-4odHZDNkzXAM7qO7kSLZqQBs.png?st=2023-10-28T23%3A20%3A57Z&se=2023-10-29T01%3A20%3A57Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2023-10-28T23%3A25%3A45Z&ske=2023-10-29T23%3A25%3A45Z&sks=b&skv=2021-08-06&sig=/PDp9gdv6ycGjITNHwhQLZzj2v4BTH8avpiwg6NTBW8%3D',\n",
       " 'description': \"Recently I made my first contribution to an open source project, LangChain. \\nLooking at the source code, the fix was simple. However, adding my change to the project turned out to be more complicated than expected.\\nI did not know how to test my updated code to ensure it worked as expected. The project gave instructions for testing the code, but I did not understand how to run them.\\nLuckily, one of the project's maintainers simply accepted my change and made further revisions.\\n\\nI'd love to learn how to contribute code to open source Python packages. If you have a great resource on this or a great beginner-friendly project to contribute to, please let me know!\",\n",
       " 'prompt': PromptTemplate(input_variables=['text'], output_parser=None, partial_variables={}, template=\"\\nYou create content on LinkedIn with the goal of building the writer's professional brand as a data scientist who is continuously developing her skills. \\nThe writer is an Asian female who has her hair in a bun. Write a prompt to generate a cartoon image to accompany this LinkedIn post: {text}\\n: {text}\", template_format='f-string', validate_template=True),\n",
       " 'image_prompt': 'Prompt for Cartoon Image: An Asian female data scientist with her hair in a bun, looking determined and focused as she works on her laptop, with a caption that reads: \"Taking the first step towards becoming a data scientist!\"'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_dict[iteration]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recently I made my first contribution to an open source project, LangChain. \n",
      "Looking at the source code, the fix was simple. However, adding my change to the project turned out to be more complicated than expected.\n",
      "I did not know how to test my updated code to ensure it worked as expected. The project gave instructions for testing the code, but I did not understand how to run them.\n",
      "Luckily, one of the project's maintainers simply accepted my change and made further revisions.\n",
      "\n",
      "I'd love to learn how to contribute code to open source Python packages. If you have a great resource on this or a great beginner-friendly project to contribute to, please let me know!\n",
      "\n",
      "\n",
      "PS: The 2 cartoons were generated by DALL-E (which obviously is not perfect yet). I asked OpenAI to generate the DALL-E prompt based on the text of the above post, and this was the result: \"Prompt for Cartoon Image: An Asian female data scientist with her hair in a bun, looking determined and focused as she works on her laptop, with a caption that reads: \"Taking the first step towards becoming a data scientist!\"\".\n",
      "\n",
      "PPS: If you really want to know, the prompt template I used to generate the DALL-E prompt (with the help of the LangChain `LLMChain` class) was as follows: \"You create content on LinkedIn with the goal of building the writer's professional brand as a data scientist who is continuously developing her skills. \n",
      "The writer is an Asian female who has her hair in a bun. Write a prompt to generate a cartoon image to accompany this LinkedIn post: {text}\"\n",
      "\n",
      "\n",
      "#datascience #llm \n"
     ]
    }
   ],
   "source": [
    "def print_dict_values_for_key(results_dict, key, zero_indexed=False):\n",
    "    \"\"\"\n",
    "    Prints the values of a dictionary for a given key.\n",
    "\n",
    "    Parameters:\n",
    "    - results_dict (dict): Dictionary to print values for.\n",
    "    - key (str): Dictionary key to print values for.\n",
    "    - zero_indexed (bool): If True, prints the index of each value starting from 0. If False, prints the index starting from 1.\n",
    "        \"\"\"\n",
    "    for index, item in enumerate(results_dict):\n",
    "        print(f\"{index+1 if zero_indexed==False else index}: {results_dict[item].get(key, 'None').strip()}\", end='\\n\\n')\n",
    "\n",
    "def create_linkedin_post(results_dict, iteration, hashtags=['datascience', 'llm']):\n",
    "    print(results_dict[iteration]['description'])\n",
    "    print(f'\\n\\nPS: The 2 cartoons were generated by DALL-E (which obviously is not perfect yet). I asked OpenAI to generate the DALL-E prompt based on the text of the above post, and this was the result: \"{results_dict[iteration][\"image_prompt\"].strip()}\".')\n",
    "    print(f'\\nPPS: If you really want to know, the prompt template I used to generate the DALL-E prompt (with the help of the LangChain `LLMChain` class) was as follows: \"{results_dict[iteration][\"prompt\"].template[:-8].strip()}\"')\n",
    "    print(f'\\n\\n{\"\".join([f\"#{tag} \" for tag in hashtags])}')\n",
    "\n",
    "create_linkedin_post(results_dict, iteration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2023-11-25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt template: \n",
      "You create content on LinkedIn with the goal of building the writer's professional brand as a data scientist who is continuously developing her skills. \n",
      "The writer is an Asian female who has her hair in a bun. Write a prompt to generate a cartoon image to accompany this LinkedIn post: {text}\n",
      ": {text}\n",
      "\n",
      "Input: A source of tension we face frequently in work is whether to get things done the quick and dirty way, or to take time to create a system to make that task more efficient later on.\n",
      "\n",
      "For example, should you:\n",
      "\n",
      "a) Manually copy and paste data from one place to another, or\n",
      "\n",
      "b) Write (and debug!) code that will automate this process?\n",
      "\n",
      "Choosing option b only makes sense if this task needs to be repeated. People who know how I work know that my preference is usually for option B even if it ends up taking more time (coding is my version of playing a slot machine). \n",
      "\n",
      "At the recent Big Data & Analytics West conference, Di Wu (Director Engineering, Coastal Community Bank) gave a presentation titled “Value Driven Architecture”, which gave me something else to think about: \n",
      "\n",
      "1. When dealing with clients and colleagues, it’s important to deliver wins at the start, not just focus on best practices and sustainability. \n",
      "2. Interim options are okay while working towards the target architecture.\n",
      "3. If you opt for interim options, it is important to not add technical debt that will create more hassle down the road. \n",
      "\n",
      "Point #1 is something the perfectionist side of me needs to remember. Point #3 is definitely something I’ll think about whenever my team members suggest a quick and dirty solution instead of an ideal solution.\n",
      "\n",
      "Have a related story to share? Post in the comments below!\n",
      "\n",
      "#bigdata\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "You create content on LinkedIn with the goal of building the writer's professional brand as a data scientist who is continuously developing her skills. \n",
      "The writer is an Asian female who has her hair in a bun. Write a prompt to generate a cartoon image to accompany this LinkedIn post: A source of tension we face frequently in work is whether to get things done the quick and dirty way, or to take time to create a system to make that task more efficient later on.\n",
      "\n",
      "For example, should you:\n",
      "\n",
      "a) Manually copy and paste data from one place to another, or\n",
      "\n",
      "b) Write (and debug!) code that will automate this process?\n",
      "\n",
      "Choosing option b only makes sense if this task needs to be repeated. People who know how I work know that my preference is usually for option B even if it ends up taking more time (coding is my version of playing a slot machine). \n",
      "\n",
      "At the recent Big Data & Analytics West conference, Di Wu (Director Engineering, Coastal Community Bank) gave a presentation titled “Value Driven Architecture”, which gave me something else to think about: \n",
      "\n",
      "1. When dealing with clients and colleagues, it’s important to deliver wins at the start, not just focus on best practices and sustainability. \n",
      "2. Interim options are okay while working towards the target architecture.\n",
      "3. If you opt for interim options, it is important to not add technical debt that will create more hassle down the road. \n",
      "\n",
      "Point #1 is something the perfectionist side of me needs to remember. Point #3 is definitely something I’ll think about whenever my team members suggest a quick and dirty solution instead of an ideal solution.\n",
      "\n",
      "Have a related story to share? Post in the comments below!\n",
      "\n",
      "#bigdata\n",
      ": A source of tension we face frequently in work is whether to get things done the quick and dirty way, or to take time to create a system to make that task more efficient later on.\n",
      "\n",
      "For example, should you:\n",
      "\n",
      "a) Manually copy and paste data from one place to another, or\n",
      "\n",
      "b) Write (and debug!) code that will automate this process?\n",
      "\n",
      "Choosing option b only makes sense if this task needs to be repeated. People who know how I work know that my preference is usually for option B even if it ends up taking more time (coding is my version of playing a slot machine). \n",
      "\n",
      "At the recent Big Data & Analytics West conference, Di Wu (Director Engineering, Coastal Community Bank) gave a presentation titled “Value Driven Architecture”, which gave me something else to think about: \n",
      "\n",
      "1. When dealing with clients and colleagues, it’s important to deliver wins at the start, not just focus on best practices and sustainability. \n",
      "2. Interim options are okay while working towards the target architecture.\n",
      "3. If you opt for interim options, it is important to not add technical debt that will create more hassle down the road. \n",
      "\n",
      "Point #1 is something the perfectionist side of me needs to remember. Point #3 is definitely something I’ll think about whenever my team members suggest a quick and dirty solution instead of an ideal solution.\n",
      "\n",
      "Have a related story to share? Post in the comments below!\n",
      "\n",
      "#bigdata\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Image prompt: Prompt for Cartoon Image: An Asian female data scientist with her hair in a bun is standing in front of a computer, debating whether to take the quick and dirty route or to take the time to create a system that will make the task more efficient in the long run.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'openai' has no attribute 'Image'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\silvh\\OneDrive\\lighthouse\\portfolio-projects\\AI-content\\notebooks\\2023-09-12 DALL-E experimentation.ipynb Cell 43\u001b[0m line \u001b[0;36m8\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/AI-content/notebooks/2023-09-12%20DALL-E%20experimentation.ipynb#Y104sZmlsZQ%3D%3D?line=77'>78</a>\u001b[0m template \u001b[39m=\u001b[39m \u001b[39m\"\"\"\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/AI-content/notebooks/2023-09-12%20DALL-E%20experimentation.ipynb#Y104sZmlsZQ%3D%3D?line=78'>79</a>\u001b[0m \u001b[39mYou create content on LinkedIn with the goal of building the writer\u001b[39m\u001b[39m'\u001b[39m\u001b[39ms professional brand as a data scientist who is continuously developing her skills. \u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/AI-content/notebooks/2023-09-12%20DALL-E%20experimentation.ipynb#Y104sZmlsZQ%3D%3D?line=79'>80</a>\u001b[0m \u001b[39mThe writer is an Asian female who has her hair in a bun. Write a prompt to generate a cartoon image to accompany this LinkedIn post: \u001b[39m\u001b[39m{text}\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/AI-content/notebooks/2023-09-12%20DALL-E%20experimentation.ipynb#Y104sZmlsZQ%3D%3D?line=80'>81</a>\u001b[0m \u001b[39m\"\"\"\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/AI-content/notebooks/2023-09-12%20DALL-E%20experimentation.ipynb#Y104sZmlsZQ%3D%3D?line=82'>83</a>\u001b[0m iteration \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/AI-content/notebooks/2023-09-12%20DALL-E%20experimentation.ipynb#Y104sZmlsZQ%3D%3D?line=83'>84</a>\u001b[0m results_dict[iteration] \u001b[39m=\u001b[39m get_dalle_image(post, template\u001b[39m=\u001b[39mtemplate, temperature\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;32mc:\\Users\\silvh\\OneDrive\\lighthouse\\portfolio-projects\\AI-content\\notebooks\\2023-09-12 DALL-E experimentation.ipynb Cell 43\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/AI-content/notebooks/2023-09-12%20DALL-E%20experimentation.ipynb#Y104sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m image_prompt \u001b[39m=\u001b[39m chain\u001b[39m.\u001b[39mrun(text)\u001b[39m.\u001b[39mstrip()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/AI-content/notebooks/2023-09-12%20DALL-E%20experimentation.ipynb#Y104sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mImage prompt: \u001b[39m\u001b[39m{\u001b[39;00mimage_prompt\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/AI-content/notebooks/2023-09-12%20DALL-E%20experimentation.ipynb#Y104sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m image_url \u001b[39m=\u001b[39m DallEAPIWrapper(n\u001b[39m=\u001b[39mn)\u001b[39m.\u001b[39mrun(image_prompt)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/AI-content/notebooks/2023-09-12%20DALL-E%20experimentation.ipynb#Y104sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m results \u001b[39m=\u001b[39m {\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/AI-content/notebooks/2023-09-12%20DALL-E%20experimentation.ipynb#Y104sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mimage_url\u001b[39m\u001b[39m'\u001b[39m: image_url, \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/AI-content/notebooks/2023-09-12%20DALL-E%20experimentation.ipynb#Y104sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mdescription\u001b[39m\u001b[39m'\u001b[39m: text,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/AI-content/notebooks/2023-09-12%20DALL-E%20experimentation.ipynb#Y104sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mprompt\u001b[39m\u001b[39m'\u001b[39m: prompt,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/AI-content/notebooks/2023-09-12%20DALL-E%20experimentation.ipynb#Y104sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mimage_prompt\u001b[39m\u001b[39m'\u001b[39m: image_prompt\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/AI-content/notebooks/2023-09-12%20DALL-E%20experimentation.ipynb#Y104sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m     }\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/AI-content/notebooks/2023-09-12%20DALL-E%20experimentation.ipynb#Y104sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39mreturn\u001b[39;00m results\n",
      "File \u001b[1;32mc:\\Users\\silvh\\.conda\\envs\\projects\\Lib\\site-packages\\pydantic\\v1\\main.py:339\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[1;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[39mCreate a new model by parsing and validating input data from keyword arguments.\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[0;32m    336\u001b[0m \u001b[39mRaises ValidationError if the input data cannot be parsed to form a valid model.\u001b[39;00m\n\u001b[0;32m    337\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    338\u001b[0m \u001b[39m# Uses something other than `self` the first arg to allow \"self\" as a settable attribute\u001b[39;00m\n\u001b[1;32m--> 339\u001b[0m values, fields_set, validation_error \u001b[39m=\u001b[39m validate_model(__pydantic_self__\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m, data)\n\u001b[0;32m    340\u001b[0m \u001b[39mif\u001b[39;00m validation_error:\n\u001b[0;32m    341\u001b[0m     \u001b[39mraise\u001b[39;00m validation_error\n",
      "File \u001b[1;32mc:\\Users\\silvh\\.conda\\envs\\projects\\Lib\\site-packages\\pydantic\\v1\\main.py:1102\u001b[0m, in \u001b[0;36mvalidate_model\u001b[1;34m(model, input_data, cls)\u001b[0m\n\u001b[0;32m   1100\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m   1101\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1102\u001b[0m     values \u001b[39m=\u001b[39m validator(cls_, values)\n\u001b[0;32m   1103\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mValueError\u001b[39;00m, \u001b[39mTypeError\u001b[39;00m, \u001b[39mAssertionError\u001b[39;00m) \u001b[39mas\u001b[39;00m exc:\n\u001b[0;32m   1104\u001b[0m     errors\u001b[39m.\u001b[39mappend(ErrorWrapper(exc, loc\u001b[39m=\u001b[39mROOT_KEY))\n",
      "File \u001b[1;32mc:\\Users\\silvh\\.conda\\envs\\projects\\Lib\\site-packages\\langchain\\utilities\\dalle_image_generator.py:40\u001b[0m, in \u001b[0;36mDallEAPIWrapper.validate_environment\u001b[1;34m(cls, values)\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mopenai\u001b[39;00m\n\u001b[0;32m     39\u001b[0m     openai\u001b[39m.\u001b[39mapi_key \u001b[39m=\u001b[39m openai_api_key\n\u001b[1;32m---> 40\u001b[0m     values[\u001b[39m\"\u001b[39m\u001b[39mclient\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39mImage\n\u001b[0;32m     41\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     42\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\n\u001b[0;32m     43\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCould not import openai python package. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     44\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPlease it install it with `pip install openai`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     45\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'openai' has no attribute 'Image'"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "import os\n",
    "from langchain.utilities.dalle_image_generator import DallEAPIWrapper\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "def get_dalle_image(text, n=3, temperature=1, template=None, verbose=False, max_retries=1, max_tokens=900):\n",
    "    llm = OpenAI(\n",
    "        temperature=temperature, openai_organization=os.environ['openai_organization'],\n",
    "        max_retries=max_retries, max_tokens=max_tokens\n",
    "        )\n",
    "    text = text.strip()\n",
    "    if template:\n",
    "        template=template + ': {text}'\n",
    "    else:\n",
    "        template=\"Generate a detailed prompt to generate an image based on the following social media post: {text}\"\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"text\"],\n",
    "        template=template,\n",
    "    )\n",
    "    print(f'Prompt template: {prompt.template}')\n",
    "    print(f'\\nInput: {text}')\n",
    "    chain = LLMChain(llm=llm, prompt=prompt, verbose=verbose)\n",
    "    image_prompt = chain.run(text).strip()\n",
    "    print(f'\\nImage prompt: {image_prompt}')\n",
    "    image_url = DallEAPIWrapper(n=n).run(image_prompt)\n",
    "    results = {\n",
    "        'image_url': image_url, \n",
    "        'description': text,\n",
    "        'prompt': prompt,\n",
    "        'image_prompt': image_prompt\n",
    "        }\n",
    "    return results\n",
    "\n",
    "def print_dict_values_for_key(results_dict, key, zero_indexed=False):\n",
    "    \"\"\"\n",
    "    Prints the values of a dictionary for a given key.\n",
    "\n",
    "    Parameters:\n",
    "    - results_dict (dict): Dictionary to print values for.\n",
    "    - key (str): Dictionary key to print values for.\n",
    "    - zero_indexed (bool): If True, prints the index of each value starting from 0. If False, prints the index starting from 1.\n",
    "        \"\"\"\n",
    "    for index, item in enumerate(results_dict):\n",
    "        print(f\"{index+1 if zero_indexed==False else index}: {results_dict[item].get(key, 'None').strip()}\", end='\\n\\n')\n",
    "\n",
    "def create_linkedin_post(results_dict, iteration, hashtags=['datascience', 'llm']):\n",
    "    print(results_dict[iteration]['description'])\n",
    "    print(f'\\n\\nPS: The 2 cartoons were generated by DALL-E (which obviously is not perfect yet). I asked OpenAI to generate the DALL-E prompt based on the text of the above post, and this was the result: \"{results_dict[iteration][\"image_prompt\"].strip()}\".')\n",
    "    print(f'\\nPPS: If you really want to know, the prompt template I used to generate the DALL-E prompt (with the help of the LangChain `LLMChain` class) was as follows: \"{results_dict[iteration][\"prompt\"].template[:-8].strip()}\"')\n",
    "    print(f'\\n\\n{\"\".join([f\"#{tag} \" for tag in hashtags])}')\n",
    "\n",
    "post = \"\"\"\n",
    "A source of tension we face frequently in work is whether to get things done the quick and dirty way, or to take time to create a system to make that task more efficient later on.\n",
    "\n",
    "For example, should you:\n",
    "\n",
    "a) Manually copy and paste data from one place to another, or\n",
    "\n",
    "b) Write (and debug!) code that will automate this process?\n",
    "\n",
    "Choosing option b only makes sense if this task needs to be repeated. People who know how I work know that my preference is usually for option B even if it ends up taking more time (coding is my version of playing a slot machine). \n",
    "\n",
    "At the recent Big Data & Analytics West conference, Di Wu (Director Engineering, Coastal Community Bank) gave a presentation titled “Value Driven Architecture”, which gave me something else to think about: \n",
    "\n",
    "1. When dealing with clients and colleagues, it’s important to deliver wins at the start, not just focus on best practices and sustainability. \n",
    "2. Interim options are okay while working towards the target architecture.\n",
    "3. If you opt for interim options, it is important to not add technical debt that will create more hassle down the road. \n",
    "\n",
    "Point #1 is something the perfectionist side of me needs to remember. Point #3 is definitely something I’ll think about whenever my team members suggest a quick and dirty solution instead of an ideal solution.\n",
    "\n",
    "Have a related story to share? Post in the comments below!\n",
    "\n",
    "#bigdata\n",
    "\"\"\"\n",
    "\n",
    "template = \"\"\"\n",
    "You create content on LinkedIn with the goal of building the writer's professional brand as a data scientist who is continuously developing her skills. \n",
    "The writer is an Asian female who has her hair in a bun. Write a prompt to generate a cartoon image to accompany this LinkedIn post: {text}\n",
    "\"\"\"\n",
    "\n",
    "iteration = 1\n",
    "results_dict[iteration] = get_dalle_image(post, template=template, temperature=0, verbose=True)\n",
    "\n",
    "# create_linkedin_post(results_dict, iteration)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *End of Page*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "11938c6bc6919ae2720b4d5011047913343b08a43b18698fd82dedb0d4417594"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
