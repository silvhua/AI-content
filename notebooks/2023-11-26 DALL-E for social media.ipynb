{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Title\n",
    "[]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\custom_python\")\n",
    "sys.path.append(r'C:\\Users\\silvh\\OneDrive\\lighthouse\\portfolio-projects\\langchain\\libs\\langchain\\langchain\\utilities')\n",
    "from silvhua import *\n",
    "# from datetime import datetime\n",
    "# sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\portfolio-projects\\online-PT-social-media-NLP\\src\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = dict()\n",
    "descriptions = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2023-11-25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt template: \n",
      "You create content on LinkedIn with the goal of building the writer's professional brand as a data scientist who is continuously developing her skills. \n",
      "The writer is an Asian female who has her hair in a bun. Write a prompt to generate a cartoon image to accompany this LinkedIn post: {text}\n",
      ": {text}\n",
      "\n",
      "Input: A source of tension we face frequently in work is whether to get things done the quick and dirty way, or to take time to create a system to make that task more efficient later on.\n",
      "\n",
      "For example, should you:\n",
      "\n",
      "a) Manually copy and paste data from one place to another, or\n",
      "\n",
      "b) Write (and debug!) code that will automate this process?\n",
      "\n",
      "Choosing option b only makes sense if this task needs to be repeated. People who know how I work know that my preference is usually for option B even if it ends up taking more time (coding is my version of playing a slot machine). \n",
      "\n",
      "At the recent Big Data & Analytics West conference, Di Wu (Director Engineering, Coastal Community Bank) gave a presentation titled “Value Driven Architecture”, which gave me something else to think about: \n",
      "\n",
      "1. When dealing with clients and colleagues, it’s important to deliver wins at the start, not just focus on best practices and sustainability. \n",
      "2. Interim options are okay while working towards the target architecture.\n",
      "3. If you opt for interim options, it is important to not add technical debt that will create more hassle down the road. \n",
      "\n",
      "Point #1 is something the perfectionist side of me needs to remember. Point #3 is definitely something I’ll think about whenever my team members suggest a quick and dirty solution instead of an ideal solution.\n",
      "\n",
      "Have a related story to share? Post in the comments below!\n",
      "\n",
      "#bigdata\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "You create content on LinkedIn with the goal of building the writer's professional brand as a data scientist who is continuously developing her skills. \n",
      "The writer is an Asian female who has her hair in a bun. Write a prompt to generate a cartoon image to accompany this LinkedIn post: A source of tension we face frequently in work is whether to get things done the quick and dirty way, or to take time to create a system to make that task more efficient later on.\n",
      "\n",
      "For example, should you:\n",
      "\n",
      "a) Manually copy and paste data from one place to another, or\n",
      "\n",
      "b) Write (and debug!) code that will automate this process?\n",
      "\n",
      "Choosing option b only makes sense if this task needs to be repeated. People who know how I work know that my preference is usually for option B even if it ends up taking more time (coding is my version of playing a slot machine). \n",
      "\n",
      "At the recent Big Data & Analytics West conference, Di Wu (Director Engineering, Coastal Community Bank) gave a presentation titled “Value Driven Architecture”, which gave me something else to think about: \n",
      "\n",
      "1. When dealing with clients and colleagues, it’s important to deliver wins at the start, not just focus on best practices and sustainability. \n",
      "2. Interim options are okay while working towards the target architecture.\n",
      "3. If you opt for interim options, it is important to not add technical debt that will create more hassle down the road. \n",
      "\n",
      "Point #1 is something the perfectionist side of me needs to remember. Point #3 is definitely something I’ll think about whenever my team members suggest a quick and dirty solution instead of an ideal solution.\n",
      "\n",
      "Have a related story to share? Post in the comments below!\n",
      "\n",
      "#bigdata\n",
      ": A source of tension we face frequently in work is whether to get things done the quick and dirty way, or to take time to create a system to make that task more efficient later on.\n",
      "\n",
      "For example, should you:\n",
      "\n",
      "a) Manually copy and paste data from one place to another, or\n",
      "\n",
      "b) Write (and debug!) code that will automate this process?\n",
      "\n",
      "Choosing option b only makes sense if this task needs to be repeated. People who know how I work know that my preference is usually for option B even if it ends up taking more time (coding is my version of playing a slot machine). \n",
      "\n",
      "At the recent Big Data & Analytics West conference, Di Wu (Director Engineering, Coastal Community Bank) gave a presentation titled “Value Driven Architecture”, which gave me something else to think about: \n",
      "\n",
      "1. When dealing with clients and colleagues, it’s important to deliver wins at the start, not just focus on best practices and sustainability. \n",
      "2. Interim options are okay while working towards the target architecture.\n",
      "3. If you opt for interim options, it is important to not add technical debt that will create more hassle down the road. \n",
      "\n",
      "Point #1 is something the perfectionist side of me needs to remember. Point #3 is definitely something I’ll think about whenever my team members suggest a quick and dirty solution instead of an ideal solution.\n",
      "\n",
      "Have a related story to share? Post in the comments below!\n",
      "\n",
      "#bigdata\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Image prompt: Prompt for Cartoon Image: An Asian female data scientist with her hair in a bun is standing in front of a computer, debating whether to take the quick and dirty route or to take the time to create a system that will make the task more efficient in the long run.\n",
      "An error occurred on line 28 in C:\\Users\\silvh\\AppData\\Local\\Temp\\ipykernel_18528\\1798320.py : module 'openai' has no attribute 'Image'\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "import os\n",
    "from langchain.utilities.dalle_image_generator import DallEAPIWrapper\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "def get_dalle_image(text, n=3, temperature=1, template=None, verbose=False, max_retries=1, max_tokens=900):\n",
    "    llm = OpenAI(\n",
    "        temperature=temperature, openai_organization=os.environ['openai_organization'],\n",
    "        max_retries=max_retries, max_tokens=max_tokens\n",
    "        )\n",
    "    text = text.strip()\n",
    "    if template:\n",
    "        template=template + ': {text}'\n",
    "    else:\n",
    "        template=\"Generate a detailed prompt to generate an image based on the following social media post: {text}\"\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"text\"],\n",
    "        template=template,\n",
    "    )\n",
    "    print(f'Prompt template: {prompt.template}')\n",
    "    print(f'\\nInput: {text}')\n",
    "    chain = LLMChain(llm=llm, prompt=prompt, verbose=verbose)\n",
    "    image_prompt = chain.run(text).strip()\n",
    "    print(f'\\nImage prompt: {image_prompt}')\n",
    "    try:\n",
    "        image_url = DallEAPIWrapper(n=n).run(image_prompt)\n",
    "    except Exception as error:\n",
    "        exc_type, exc_obj, tb = sys.exc_info()\n",
    "        f = tb.tb_frame\n",
    "        lineno = tb.tb_lineno\n",
    "        filename = f.f_code.co_filename\n",
    "        print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "        image_url = None\n",
    "\n",
    "    results = {\n",
    "        'image_url': image_url, \n",
    "        'description': text,\n",
    "        'prompt': prompt,\n",
    "        'image_prompt': image_prompt\n",
    "        }\n",
    "    return results\n",
    "\n",
    "def print_dict_values_for_key(results_dict, key, zero_indexed=False):\n",
    "    \"\"\"\n",
    "    Prints the values of a dictionary for a given key.\n",
    "\n",
    "    Parameters:\n",
    "    - results_dict (dict): Dictionary to print values for.\n",
    "    - key (str): Dictionary key to print values for.\n",
    "    - zero_indexed (bool): If True, prints the index of each value starting from 0. If False, prints the index starting from 1.\n",
    "        \"\"\"\n",
    "    for index, item in enumerate(results_dict):\n",
    "        print(f\"{index+1 if zero_indexed==False else index}: {results_dict[item].get(key, 'None').strip()}\", end='\\n\\n')\n",
    "\n",
    "def create_linkedin_post(results_dict, iteration, hashtags=['datascience', 'llm']):\n",
    "    print(results_dict[iteration]['description'])\n",
    "    print(f'\\n\\nPS: The 2 cartoons were generated by DALL-E (which obviously is not perfect yet). I asked OpenAI to generate the DALL-E prompt based on the text of the above post, and this was the result: \"{results_dict[iteration][\"image_prompt\"].strip()}\".')\n",
    "    print(f'\\nPPS: If you really want to know, the prompt template I used to generate the DALL-E prompt (with the help of the LangChain `LLMChain` class) was as follows: \"{results_dict[iteration][\"prompt\"].template[:-8].strip()}\"')\n",
    "    print(f'\\n\\n{\"\".join([f\"#{tag} \" for tag in hashtags])}')\n",
    "\n",
    "post = \"\"\"\n",
    "A source of tension we face frequently in work is whether to get things done the quick and dirty way, or to take time to create a system to make that task more efficient later on.\n",
    "\n",
    "For example, should you:\n",
    "\n",
    "a) Manually copy and paste data from one place to another, or\n",
    "\n",
    "b) Write (and debug!) code that will automate this process?\n",
    "\n",
    "Choosing option b only makes sense if this task needs to be repeated. People who know how I work know that my preference is usually for option B even if it ends up taking more time (coding is my version of playing a slot machine). \n",
    "\n",
    "At the recent Big Data & Analytics West conference, Di Wu (Director Engineering, Coastal Community Bank) gave a presentation titled “Value Driven Architecture”, which gave me something else to think about: \n",
    "\n",
    "1. When dealing with clients and colleagues, it’s important to deliver wins at the start, not just focus on best practices and sustainability. \n",
    "2. Interim options are okay while working towards the target architecture.\n",
    "3. If you opt for interim options, it is important to not add technical debt that will create more hassle down the road. \n",
    "\n",
    "Point #1 is something the perfectionist side of me needs to remember. Point #3 is definitely something I’ll think about whenever my team members suggest a quick and dirty solution instead of an ideal solution.\n",
    "\n",
    "Have a related story to share? Post in the comments below!\n",
    "\n",
    "#bigdata\n",
    "\"\"\"\n",
    "\n",
    "template = \"\"\"\n",
    "You create content on LinkedIn with the goal of building the writer's professional brand as a data scientist who is continuously developing her skills. \n",
    "The writer is an Asian female who has her hair in a bun. Write a prompt to generate a cartoon image to accompany this LinkedIn post: {text}\n",
    "\"\"\"\n",
    "\n",
    "iteration = 1\n",
    "results_dict[iteration] = get_dalle_image(post, template=template, temperature=0, verbose=True)\n",
    "\n",
    "# create_linkedin_post(results_dict, iteration)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## iteration 2: fix `DallEAPIWrapper`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain_core'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\silvh\\OneDrive\\lighthouse\\portfolio-projects\\AI-content\\notebooks\\2023-11-26 DALL-E for social media.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/AI-content/notebooks/2023-11-26%20DALL-E%20for%20social%20media.ipynb#Y111sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdalle_image_generator\u001b[39;00m \u001b[39mimport\u001b[39;00m DallEAPIWrapper\n",
      "File \u001b[1;32m~\\OneDrive\\lighthouse\\portfolio-projects\\langchain\\libs\\langchain\\langchain\\utilities\\dalle_image_generator.py:4\u001b[0m\n\u001b[0;32m      1\u001b[0m \"\"\"Utility that calls OpenAI's Dall-E Image Generator.\"\"\"\n\u001b[0;32m      2\u001b[0m # from typing import Any, Dict, Optional\n\u001b[0;32m      3\u001b[0m \n\u001b[1;32m----> 4\u001b[0m # from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator\n\u001b[0;32m      5\u001b[0m \n\u001b[0;32m      6\u001b[0m # from langchain.utils import get_from_dict_or_env\n\u001b[0;32m      9\u001b[0m class DallEAPIWrapper(BaseModel):\n\u001b[0;32m     10\u001b[0m     \"\"\"Wrapper for OpenAI's DALL-E Image Generator.\n\u001b[0;32m     11\u001b[0m \n\u001b[0;32m     12\u001b[0m     https://platform.openai.com/docs/guides/images/generations?context=node\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     17\u001b[0m     2. save your OPENAI_API_KEY in an environment variable\n\u001b[0;32m     18\u001b[0m     \"\"\"\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'langchain_core'"
     ]
    }
   ],
   "source": [
    "from dalle_image_generator import DallEAPIWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sys.path.append(r'C:\\Users\\silvh\\OneDrive\\lighthouse\\portfolio-projects\\langchain\\libs\\core')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dalle_image_generator import DallEAPIWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt template: \n",
      "You create content on LinkedIn with the goal of building the writer's professional brand as a data scientist who is continuously developing her skills. \n",
      "The writer is an Asian female who has her hair in a bun. Write a prompt to generate a cartoon image to accompany this LinkedIn post: {text}\n",
      ": {text}\n",
      "\n",
      "Input: A source of tension we face frequently in work is whether to get things done the quick and dirty way, or to take time to create a system to make that task more efficient later on.\n",
      "\n",
      "For example, should you:\n",
      "\n",
      "a) Manually copy and paste data from one place to another, or\n",
      "\n",
      "b) Write (and debug!) code that will automate this process?\n",
      "\n",
      "Choosing option b only makes sense if this task needs to be repeated. People who know how I work know that my preference is usually for option B even if it ends up taking more time (coding is my version of playing a slot machine). \n",
      "\n",
      "At the recent Big Data & Analytics West conference, Di Wu (Director Engineering, Coastal Community Bank) gave a presentation titled “Value Driven Architecture”, which gave me something else to think about: \n",
      "\n",
      "1. When dealing with clients and colleagues, it’s important to deliver wins at the start, not just focus on best practices and sustainability. \n",
      "2. Interim options are okay while working towards the target architecture.\n",
      "3. If you opt for interim options, it is important to not add technical debt that will create more hassle down the road. \n",
      "\n",
      "Point #1 is something the perfectionist side of me needs to remember. Point #3 is definitely something I’ll think about whenever my team members suggest a quick and dirty solution instead of an ideal solution.\n",
      "\n",
      "Have a related story to share? Post in the comments below!\n",
      "\n",
      "#bigdata\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "You create content on LinkedIn with the goal of building the writer's professional brand as a data scientist who is continuously developing her skills. \n",
      "The writer is an Asian female who has her hair in a bun. Write a prompt to generate a cartoon image to accompany this LinkedIn post: A source of tension we face frequently in work is whether to get things done the quick and dirty way, or to take time to create a system to make that task more efficient later on.\n",
      "\n",
      "For example, should you:\n",
      "\n",
      "a) Manually copy and paste data from one place to another, or\n",
      "\n",
      "b) Write (and debug!) code that will automate this process?\n",
      "\n",
      "Choosing option b only makes sense if this task needs to be repeated. People who know how I work know that my preference is usually for option B even if it ends up taking more time (coding is my version of playing a slot machine). \n",
      "\n",
      "At the recent Big Data & Analytics West conference, Di Wu (Director Engineering, Coastal Community Bank) gave a presentation titled “Value Driven Architecture”, which gave me something else to think about: \n",
      "\n",
      "1. When dealing with clients and colleagues, it’s important to deliver wins at the start, not just focus on best practices and sustainability. \n",
      "2. Interim options are okay while working towards the target architecture.\n",
      "3. If you opt for interim options, it is important to not add technical debt that will create more hassle down the road. \n",
      "\n",
      "Point #1 is something the perfectionist side of me needs to remember. Point #3 is definitely something I’ll think about whenever my team members suggest a quick and dirty solution instead of an ideal solution.\n",
      "\n",
      "Have a related story to share? Post in the comments below!\n",
      "\n",
      "#bigdata\n",
      ": A source of tension we face frequently in work is whether to get things done the quick and dirty way, or to take time to create a system to make that task more efficient later on.\n",
      "\n",
      "For example, should you:\n",
      "\n",
      "a) Manually copy and paste data from one place to another, or\n",
      "\n",
      "b) Write (and debug!) code that will automate this process?\n",
      "\n",
      "Choosing option b only makes sense if this task needs to be repeated. People who know how I work know that my preference is usually for option B even if it ends up taking more time (coding is my version of playing a slot machine). \n",
      "\n",
      "At the recent Big Data & Analytics West conference, Di Wu (Director Engineering, Coastal Community Bank) gave a presentation titled “Value Driven Architecture”, which gave me something else to think about: \n",
      "\n",
      "1. When dealing with clients and colleagues, it’s important to deliver wins at the start, not just focus on best practices and sustainability. \n",
      "2. Interim options are okay while working towards the target architecture.\n",
      "3. If you opt for interim options, it is important to not add technical debt that will create more hassle down the road. \n",
      "\n",
      "Point #1 is something the perfectionist side of me needs to remember. Point #3 is definitely something I’ll think about whenever my team members suggest a quick and dirty solution instead of an ideal solution.\n",
      "\n",
      "Have a related story to share? Post in the comments below!\n",
      "\n",
      "#bigdata\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Image prompt: Prompt for Cartoon Image: An Asian female data scientist with her hair in a bun is standing in front of a computer, debating whether to take the quick and dirty route or to take the time to create a system that will make the task more efficient in the long run.\n",
      "An error occurred on line 29 in C:\\Users\\silvh\\AppData\\Local\\Temp\\ipykernel_16704\\2008873357.py : 'DallEAPIWrapper' object has no attribute 'qualtity'\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'results_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\silvh\\OneDrive\\lighthouse\\portfolio-projects\\AI-content\\notebooks\\2023-11-26 DALL-E for social media.ipynb Cell 11\u001b[0m line \u001b[0;36m9\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/AI-content/notebooks/2023-11-26%20DALL-E%20for%20social%20media.ipynb#X62sZmlsZQ%3D%3D?line=87'>88</a>\u001b[0m template \u001b[39m=\u001b[39m \u001b[39m\"\"\"\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/AI-content/notebooks/2023-11-26%20DALL-E%20for%20social%20media.ipynb#X62sZmlsZQ%3D%3D?line=88'>89</a>\u001b[0m \u001b[39mYou create content on LinkedIn with the goal of building the writer\u001b[39m\u001b[39m'\u001b[39m\u001b[39ms professional brand as a data scientist who is continuously developing her skills. \u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/AI-content/notebooks/2023-11-26%20DALL-E%20for%20social%20media.ipynb#X62sZmlsZQ%3D%3D?line=89'>90</a>\u001b[0m \u001b[39mThe writer is an Asian female who has her hair in a bun. Write a prompt to generate a cartoon image to accompany this LinkedIn post: \u001b[39m\u001b[39m{text}\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/AI-content/notebooks/2023-11-26%20DALL-E%20for%20social%20media.ipynb#X62sZmlsZQ%3D%3D?line=90'>91</a>\u001b[0m \u001b[39m\"\"\"\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/AI-content/notebooks/2023-11-26%20DALL-E%20for%20social%20media.ipynb#X62sZmlsZQ%3D%3D?line=92'>93</a>\u001b[0m iteration \u001b[39m=\u001b[39m \u001b[39m2\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/AI-content/notebooks/2023-11-26%20DALL-E%20for%20social%20media.ipynb#X62sZmlsZQ%3D%3D?line=93'>94</a>\u001b[0m results_dict[iteration] \u001b[39m=\u001b[39m get_dalle_image(post, template\u001b[39m=\u001b[39mtemplate, temperature\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'results_dict' is not defined"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "import os\n",
    "# from langchain.utilities.dalle_image_generator import DallEAPIWrapper\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import OpenAI\n",
    "from dalle_image_generator import DallEAPIWrapper\n",
    "\n",
    "def get_dalle_image(text, n=3, temperature=1, template=None, verbose=False, max_retries=1, max_tokens=900):\n",
    "    llm = OpenAI(\n",
    "        temperature=temperature, openai_organization=os.environ['openai_organization'],\n",
    "        max_retries=max_retries, max_tokens=max_tokens\n",
    "        )\n",
    "    text = text.strip()\n",
    "    if template:\n",
    "        template=template + ': {text}'\n",
    "    else:\n",
    "        template=\"Generate a detailed prompt to generate an image based on the following social media post: {text}\"\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"text\"],\n",
    "        template=template,\n",
    "    )\n",
    "    print(f'Prompt template: {prompt.template}')\n",
    "    print(f'\\nInput: {text}')\n",
    "    chain = LLMChain(llm=llm, prompt=prompt, verbose=verbose)\n",
    "    image_prompt = chain.run(text).strip()\n",
    "    print(f'\\nImage prompt: {image_prompt}')\n",
    "    try:\n",
    "        image_url = DallEAPIWrapper(n=n).run(image_prompt)\n",
    "    except Exception as error:\n",
    "        exc_type, exc_obj, tb = sys.exc_info()\n",
    "        f = tb.tb_frame\n",
    "        lineno = tb.tb_lineno\n",
    "        filename = f.f_code.co_filename\n",
    "        print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "        image_url = None\n",
    "\n",
    "    results = {\n",
    "        'image_url': image_url, \n",
    "        'description': text,\n",
    "        'prompt': prompt,\n",
    "        'image_prompt': image_prompt\n",
    "        }\n",
    "    return results\n",
    "\n",
    "def print_dict_values_for_key(results_dict, key, zero_indexed=False):\n",
    "    \"\"\"\n",
    "    Prints the values of a dictionary for a given key.\n",
    "\n",
    "    Parameters:\n",
    "    - results_dict (dict): Dictionary to print values for.\n",
    "    - key (str): Dictionary key to print values for.\n",
    "    - zero_indexed (bool): If True, prints the index of each value starting from 0. If False, prints the index starting from 1.\n",
    "        \"\"\"\n",
    "    for index, item in enumerate(results_dict):\n",
    "        print(f\"{index+1 if zero_indexed==False else index}: {results_dict[item].get(key, 'None').strip()}\", end='\\n\\n')\n",
    "\n",
    "def create_linkedin_post(results_dict, iteration, hashtags=['datascience', 'llm']):\n",
    "    print(results_dict[iteration]['description'])\n",
    "    print(f'\\n\\nPS: The 2 cartoons were generated by DALL-E (which obviously is not perfect yet). I asked OpenAI to generate the DALL-E prompt based on the text of the above post, and this was the result: \"{results_dict[iteration][\"image_prompt\"].strip()}\".')\n",
    "    print(f'\\nPPS: If you really want to know, the prompt template I used to generate the DALL-E prompt (with the help of the LangChain `LLMChain` class) was as follows: \"{results_dict[iteration][\"prompt\"].template[:-8].strip()}\"')\n",
    "    print(f'\\n\\n{\"\".join([f\"#{tag} \" for tag in hashtags])}')\n",
    "\n",
    "post = \"\"\"\n",
    "A source of tension we face frequently in work is whether to get things done the quick and dirty way, or to take time to create a system to make that task more efficient later on.\n",
    "\n",
    "For example, should you:\n",
    "\n",
    "a) Manually copy and paste data from one place to another, or\n",
    "\n",
    "b) Write (and debug!) code that will automate this process?\n",
    "\n",
    "Choosing option b only makes sense if this task needs to be repeated. People who know how I work know that my preference is usually for option B even if it ends up taking more time (coding is my version of playing a slot machine). \n",
    "\n",
    "At the recent Big Data & Analytics West conference, Di Wu (Director Engineering, Coastal Community Bank) gave a presentation titled “Value Driven Architecture”, which gave me something else to think about: \n",
    "\n",
    "1. When dealing with clients and colleagues, it’s important to deliver wins at the start, not just focus on best practices and sustainability. \n",
    "2. Interim options are okay while working towards the target architecture.\n",
    "3. If you opt for interim options, it is important to not add technical debt that will create more hassle down the road. \n",
    "\n",
    "Point #1 is something the perfectionist side of me needs to remember. Point #3 is definitely something I’ll think about whenever my team members suggest a quick and dirty solution instead of an ideal solution.\n",
    "\n",
    "Have a related story to share? Post in the comments below!\n",
    "\n",
    "#bigdata\n",
    "\"\"\"\n",
    "\n",
    "template = \"\"\"\n",
    "You create content on LinkedIn with the goal of building the writer's professional brand as a data scientist who is continuously developing her skills. \n",
    "The writer is an Asian female who has her hair in a bun. Write a prompt to generate a cartoon image to accompany this LinkedIn post: {text}\n",
    "\"\"\"\n",
    "\n",
    "iteration = 2\n",
    "results_dict[iteration] = get_dalle_image(post, template=template, temperature=0, verbose=True)\n",
    "\n",
    "# create_linkedin_post(results_dict, iteration)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iteration 3 after updating DallEAPIWrapper and refreshing kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt template: \n",
      "You create content on LinkedIn with the goal of building the writer's professional brand as a data scientist who is continuously developing her skills. \n",
      "The writer is an Asian female who has her hair in a bun. Write a prompt to generate a cartoon image to accompany this LinkedIn post: {text}\n",
      ": {text}\n",
      "\n",
      "Input: A source of tension we face frequently in work is whether to get things done the quick and dirty way, or to take time to create a system to make that task more efficient later on.\n",
      "\n",
      "For example, should you:\n",
      "\n",
      "a) Manually copy and paste data from one place to another, or\n",
      "\n",
      "b) Write (and debug!) code that will automate this process?\n",
      "\n",
      "Choosing option b only makes sense if this task needs to be repeated. People who know how I work know that my preference is usually for option B even if it ends up taking more time (coding is my version of playing a slot machine). \n",
      "\n",
      "At the recent Big Data & Analytics West conference, Di Wu (Director Engineering, Coastal Community Bank) gave a presentation titled “Value Driven Architecture”, which gave me something else to think about: \n",
      "\n",
      "1. When dealing with clients and colleagues, it’s important to deliver wins at the start, not just focus on best practices and sustainability. \n",
      "2. Interim options are okay while working towards the target architecture.\n",
      "3. If you opt for interim options, it is important to not add technical debt that will create more hassle down the road. \n",
      "\n",
      "Point #1 is something the perfectionist side of me needs to remember. Point #3 is definitely something I’ll think about whenever my team members suggest a quick and dirty solution instead of an ideal solution.\n",
      "\n",
      "Have a related story to share? Post in the comments below!\n",
      "\n",
      "#bigdata\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "You create content on LinkedIn with the goal of building the writer's professional brand as a data scientist who is continuously developing her skills. \n",
      "The writer is an Asian female who has her hair in a bun. Write a prompt to generate a cartoon image to accompany this LinkedIn post: A source of tension we face frequently in work is whether to get things done the quick and dirty way, or to take time to create a system to make that task more efficient later on.\n",
      "\n",
      "For example, should you:\n",
      "\n",
      "a) Manually copy and paste data from one place to another, or\n",
      "\n",
      "b) Write (and debug!) code that will automate this process?\n",
      "\n",
      "Choosing option b only makes sense if this task needs to be repeated. People who know how I work know that my preference is usually for option B even if it ends up taking more time (coding is my version of playing a slot machine). \n",
      "\n",
      "At the recent Big Data & Analytics West conference, Di Wu (Director Engineering, Coastal Community Bank) gave a presentation titled “Value Driven Architecture”, which gave me something else to think about: \n",
      "\n",
      "1. When dealing with clients and colleagues, it’s important to deliver wins at the start, not just focus on best practices and sustainability. \n",
      "2. Interim options are okay while working towards the target architecture.\n",
      "3. If you opt for interim options, it is important to not add technical debt that will create more hassle down the road. \n",
      "\n",
      "Point #1 is something the perfectionist side of me needs to remember. Point #3 is definitely something I’ll think about whenever my team members suggest a quick and dirty solution instead of an ideal solution.\n",
      "\n",
      "Have a related story to share? Post in the comments below!\n",
      "\n",
      "#bigdata\n",
      ": A source of tension we face frequently in work is whether to get things done the quick and dirty way, or to take time to create a system to make that task more efficient later on.\n",
      "\n",
      "For example, should you:\n",
      "\n",
      "a) Manually copy and paste data from one place to another, or\n",
      "\n",
      "b) Write (and debug!) code that will automate this process?\n",
      "\n",
      "Choosing option b only makes sense if this task needs to be repeated. People who know how I work know that my preference is usually for option B even if it ends up taking more time (coding is my version of playing a slot machine). \n",
      "\n",
      "At the recent Big Data & Analytics West conference, Di Wu (Director Engineering, Coastal Community Bank) gave a presentation titled “Value Driven Architecture”, which gave me something else to think about: \n",
      "\n",
      "1. When dealing with clients and colleagues, it’s important to deliver wins at the start, not just focus on best practices and sustainability. \n",
      "2. Interim options are okay while working towards the target architecture.\n",
      "3. If you opt for interim options, it is important to not add technical debt that will create more hassle down the road. \n",
      "\n",
      "Point #1 is something the perfectionist side of me needs to remember. Point #3 is definitely something I’ll think about whenever my team members suggest a quick and dirty solution instead of an ideal solution.\n",
      "\n",
      "Have a related story to share? Post in the comments below!\n",
      "\n",
      "#bigdata\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Image prompt: Prompt for Cartoon Image: An Asian female data scientist with her hair in a bun is standing in front of a computer, debating whether to take the quick and dirty route or to take the time to create a system that will make the task more efficient in the long run.\n",
      "An error occurred on line 30 in C:\\Users\\silvh\\AppData\\Local\\Temp\\ipykernel_17212\\3303715946.py : Error code: 500 - {'error': {'code': None, 'message': 'The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID a7ede4c46dfa633a3f40c2876eae5b90 in your email.)', 'param': None, 'type': 'server_error'}}\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "import os\n",
    "# from langchain.utilities.dalle_image_generator import DallEAPIWrapper\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import OpenAI\n",
    "sys.path.append(r'C:\\Users\\silvh\\OneDrive\\lighthouse\\portfolio-projects\\langchain\\libs\\core')\n",
    "from dalle_image_generator import DallEAPIWrapper\n",
    "\n",
    "def get_dalle_image(text, n=3, temperature=1, template=None, verbose=False, max_retries=1, max_tokens=900):\n",
    "    llm = OpenAI(\n",
    "        temperature=temperature, openai_organization=os.environ['openai_organization'],\n",
    "        max_retries=max_retries, max_tokens=max_tokens\n",
    "        )\n",
    "    text = text.strip()\n",
    "    if template:\n",
    "        template=template + ': {text}'\n",
    "    else:\n",
    "        template=\"Generate a detailed prompt to generate an image based on the following social media post: {text}\"\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"text\"],\n",
    "        template=template,\n",
    "    )\n",
    "    print(f'Prompt template: {prompt.template}')\n",
    "    print(f'\\nInput: {text}')\n",
    "    chain = LLMChain(llm=llm, prompt=prompt, verbose=verbose)\n",
    "    image_prompt = chain.run(text).strip()\n",
    "    print(f'\\nImage prompt: {image_prompt}')\n",
    "    try:\n",
    "        image_url = DallEAPIWrapper(n=n).run(image_prompt)\n",
    "    except Exception as error:\n",
    "        exc_type, exc_obj, tb = sys.exc_info()\n",
    "        f = tb.tb_frame\n",
    "        lineno = tb.tb_lineno\n",
    "        filename = f.f_code.co_filename\n",
    "        print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "        image_url = None\n",
    "\n",
    "    results = {\n",
    "        'image_url': image_url, \n",
    "        'description': text,\n",
    "        'prompt': prompt,\n",
    "        'image_prompt': image_prompt\n",
    "        }\n",
    "    return results\n",
    "\n",
    "def print_dict_values_for_key(results_dict, key, zero_indexed=False):\n",
    "    \"\"\"\n",
    "    Prints the values of a dictionary for a given key.\n",
    "\n",
    "    Parameters:\n",
    "    - results_dict (dict): Dictionary to print values for.\n",
    "    - key (str): Dictionary key to print values for.\n",
    "    - zero_indexed (bool): If True, prints the index of each value starting from 0. If False, prints the index starting from 1.\n",
    "        \"\"\"\n",
    "    for index, item in enumerate(results_dict):\n",
    "        print(f\"{index+1 if zero_indexed==False else index}: {results_dict[item].get(key, 'None').strip()}\", end='\\n\\n')\n",
    "\n",
    "def create_linkedin_post(results_dict, iteration, hashtags=['datascience', 'llm']):\n",
    "    print(results_dict[iteration]['description'])\n",
    "    print(f'\\n\\nPS: The 2 cartoons were generated by DALL-E (which obviously is not perfect yet). I asked OpenAI to generate the DALL-E prompt based on the text of the above post, and this was the result: \"{results_dict[iteration][\"image_prompt\"].strip()}\".')\n",
    "    print(f'\\nPPS: If you really want to know, the prompt template I used to generate the DALL-E prompt (with the help of the LangChain `LLMChain` class) was as follows: \"{results_dict[iteration][\"prompt\"].template[:-8].strip()}\"')\n",
    "    print(f'\\n\\n{\"\".join([f\"#{tag} \" for tag in hashtags])}')\n",
    "\n",
    "post = \"\"\"\n",
    "A source of tension we face frequently in work is whether to get things done the quick and dirty way, or to take time to create a system to make that task more efficient later on.\n",
    "\n",
    "For example, should you:\n",
    "\n",
    "a) Manually copy and paste data from one place to another, or\n",
    "\n",
    "b) Write (and debug!) code that will automate this process?\n",
    "\n",
    "Choosing option b only makes sense if this task needs to be repeated. People who know how I work know that my preference is usually for option B even if it ends up taking more time (coding is my version of playing a slot machine). \n",
    "\n",
    "At the recent Big Data & Analytics West conference, Di Wu (Director Engineering, Coastal Community Bank) gave a presentation titled “Value Driven Architecture”, which gave me something else to think about: \n",
    "\n",
    "1. When dealing with clients and colleagues, it’s important to deliver wins at the start, not just focus on best practices and sustainability. \n",
    "2. Interim options are okay while working towards the target architecture.\n",
    "3. If you opt for interim options, it is important to not add technical debt that will create more hassle down the road. \n",
    "\n",
    "Point #1 is something the perfectionist side of me needs to remember. Point #3 is definitely something I’ll think about whenever my team members suggest a quick and dirty solution instead of an ideal solution.\n",
    "\n",
    "Have a related story to share? Post in the comments below!\n",
    "\n",
    "#bigdata\n",
    "\"\"\"\n",
    "\n",
    "template = \"\"\"\n",
    "You create content on LinkedIn with the goal of building the writer's professional brand as a data scientist who is continuously developing her skills. \n",
    "The writer is an Asian female who has her hair in a bun. Write a prompt to generate a cartoon image to accompany this LinkedIn post: {text}\n",
    "\"\"\"\n",
    "\n",
    "iteration = 3\n",
    "results_dict[iteration] = get_dalle_image(post, template=template, temperature=0, verbose=True)\n",
    "\n",
    "# create_linkedin_post(results_dict, iteration)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt template: \n",
      "You create content on LinkedIn with the goal of building the writer's professional brand as a data scientist who is continuously developing her skills. \n",
      "The writer is an Asian female who has her hair in a bun. Write a prompt to generate a cartoon image to accompany this LinkedIn post: {text}\n",
      ": {text}\n",
      "\n",
      "Input: A source of tension we face frequently in work is whether to get things done the quick and dirty way, or to take time to create a system to make that task more efficient later on.\n",
      "\n",
      "For example, should you:\n",
      "\n",
      "a) Manually copy and paste data from one place to another, or\n",
      "\n",
      "b) Write (and debug!) code that will automate this process?\n",
      "\n",
      "Choosing option b only makes sense if this task needs to be repeated. People who know how I work know that my preference is usually for option B even if it ends up taking more time (coding is my version of playing a slot machine). \n",
      "\n",
      "At the recent Big Data & Analytics West conference, Di Wu (Director Engineering, Coastal Community Bank) gave a presentation titled “Value Driven Architecture”, which gave me something else to think about: \n",
      "\n",
      "1. When dealing with clients and colleagues, it’s important to deliver wins at the start, not just focus on best practices and sustainability. \n",
      "2. Interim options are okay while working towards the target architecture.\n",
      "3. If you opt for interim options, it is important to not add technical debt that will create more hassle down the road. \n",
      "\n",
      "Point #1 is something the perfectionist side of me needs to remember. Point #3 is definitely something I’ll think about whenever my team members suggest a quick and dirty solution instead of an ideal solution.\n",
      "\n",
      "Have a related story to share? Post in the comments below!\n",
      "\n",
      "#bigdata\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "You create content on LinkedIn with the goal of building the writer's professional brand as a data scientist who is continuously developing her skills. \n",
      "The writer is an Asian female who has her hair in a bun. Write a prompt to generate a cartoon image to accompany this LinkedIn post: A source of tension we face frequently in work is whether to get things done the quick and dirty way, or to take time to create a system to make that task more efficient later on.\n",
      "\n",
      "For example, should you:\n",
      "\n",
      "a) Manually copy and paste data from one place to another, or\n",
      "\n",
      "b) Write (and debug!) code that will automate this process?\n",
      "\n",
      "Choosing option b only makes sense if this task needs to be repeated. People who know how I work know that my preference is usually for option B even if it ends up taking more time (coding is my version of playing a slot machine). \n",
      "\n",
      "At the recent Big Data & Analytics West conference, Di Wu (Director Engineering, Coastal Community Bank) gave a presentation titled “Value Driven Architecture”, which gave me something else to think about: \n",
      "\n",
      "1. When dealing with clients and colleagues, it’s important to deliver wins at the start, not just focus on best practices and sustainability. \n",
      "2. Interim options are okay while working towards the target architecture.\n",
      "3. If you opt for interim options, it is important to not add technical debt that will create more hassle down the road. \n",
      "\n",
      "Point #1 is something the perfectionist side of me needs to remember. Point #3 is definitely something I’ll think about whenever my team members suggest a quick and dirty solution instead of an ideal solution.\n",
      "\n",
      "Have a related story to share? Post in the comments below!\n",
      "\n",
      "#bigdata\n",
      ": A source of tension we face frequently in work is whether to get things done the quick and dirty way, or to take time to create a system to make that task more efficient later on.\n",
      "\n",
      "For example, should you:\n",
      "\n",
      "a) Manually copy and paste data from one place to another, or\n",
      "\n",
      "b) Write (and debug!) code that will automate this process?\n",
      "\n",
      "Choosing option b only makes sense if this task needs to be repeated. People who know how I work know that my preference is usually for option B even if it ends up taking more time (coding is my version of playing a slot machine). \n",
      "\n",
      "At the recent Big Data & Analytics West conference, Di Wu (Director Engineering, Coastal Community Bank) gave a presentation titled “Value Driven Architecture”, which gave me something else to think about: \n",
      "\n",
      "1. When dealing with clients and colleagues, it’s important to deliver wins at the start, not just focus on best practices and sustainability. \n",
      "2. Interim options are okay while working towards the target architecture.\n",
      "3. If you opt for interim options, it is important to not add technical debt that will create more hassle down the road. \n",
      "\n",
      "Point #1 is something the perfectionist side of me needs to remember. Point #3 is definitely something I’ll think about whenever my team members suggest a quick and dirty solution instead of an ideal solution.\n",
      "\n",
      "Have a related story to share? Post in the comments below!\n",
      "\n",
      "#bigdata\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Image prompt: Prompt for Cartoon Image: An Asian female data scientist with her hair in a bun is standing in front of a computer, debating whether to take the quick and dirty route or to take the time to create a system that will make the task more efficient in the long run.\n",
      "An error occurred on line 30 in C:\\Users\\silvh\\AppData\\Local\\Temp\\ipykernel_17212\\2480346772.py : Error code: 500 - {'error': {'code': None, 'message': 'The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID e5c46c18ac4fb1a9293ca20775927aa4 in your email.)', 'param': None, 'type': 'server_error'}}\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "import os\n",
    "# from langchain.utilities.dalle_image_generator import DallEAPIWrapper\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import OpenAI\n",
    "sys.path.append(r'C:\\Users\\silvh\\OneDrive\\lighthouse\\portfolio-projects\\langchain\\libs\\core')\n",
    "from dalle_image_generator import DallEAPIWrapper\n",
    "\n",
    "def get_dalle_image(text, n=3, temperature=1, template=None, verbose=False, max_retries=1, max_tokens=900):\n",
    "    llm = OpenAI(\n",
    "        temperature=temperature, openai_organization=os.environ['openai_organization'],\n",
    "        max_retries=max_retries, max_tokens=max_tokens\n",
    "        )\n",
    "    text = text.strip()\n",
    "    if template:\n",
    "        template=template + ': {text}'\n",
    "    else:\n",
    "        template=\"Generate a detailed prompt to generate an image based on the following social media post: {text}\"\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"text\"],\n",
    "        template=template,\n",
    "    )\n",
    "    print(f'Prompt template: {prompt.template}')\n",
    "    print(f'\\nInput: {text}')\n",
    "    chain = LLMChain(llm=llm, prompt=prompt, verbose=verbose)\n",
    "    image_prompt = chain.run(text).strip()\n",
    "    print(f'\\nImage prompt: {image_prompt}')\n",
    "    try:\n",
    "        image_url = DallEAPIWrapper(n=n).run(image_prompt)\n",
    "    except Exception as error:\n",
    "        exc_type, exc_obj, tb = sys.exc_info()\n",
    "        f = tb.tb_frame\n",
    "        lineno = tb.tb_lineno\n",
    "        filename = f.f_code.co_filename\n",
    "        print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "        image_url = None\n",
    "\n",
    "    results = {\n",
    "        'image_url': image_url, \n",
    "        'description': text,\n",
    "        'prompt': prompt,\n",
    "        'image_prompt': image_prompt\n",
    "        }\n",
    "    return results\n",
    "\n",
    "def print_dict_values_for_key(results_dict, key, zero_indexed=False):\n",
    "    \"\"\"\n",
    "    Prints the values of a dictionary for a given key.\n",
    "\n",
    "    Parameters:\n",
    "    - results_dict (dict): Dictionary to print values for.\n",
    "    - key (str): Dictionary key to print values for.\n",
    "    - zero_indexed (bool): If True, prints the index of each value starting from 0. If False, prints the index starting from 1.\n",
    "        \"\"\"\n",
    "    for index, item in enumerate(results_dict):\n",
    "        print(f\"{index+1 if zero_indexed==False else index}: {results_dict[item].get(key, 'None').strip()}\", end='\\n\\n')\n",
    "\n",
    "def create_linkedin_post(results_dict, iteration, hashtags=['datascience', 'llm']):\n",
    "    print(results_dict[iteration]['description'])\n",
    "    print(f'\\n\\nPS: The 2 cartoons were generated by DALL-E (which obviously is not perfect yet). I asked OpenAI to generate the DALL-E prompt based on the text of the above post, and this was the result: \"{results_dict[iteration][\"image_prompt\"].strip()}\".')\n",
    "    print(f'\\nPPS: If you really want to know, the prompt template I used to generate the DALL-E prompt (with the help of the LangChain `LLMChain` class) was as follows: \"{results_dict[iteration][\"prompt\"].template[:-8].strip()}\"')\n",
    "    print(f'\\n\\n{\"\".join([f\"#{tag} \" for tag in hashtags])}')\n",
    "\n",
    "post = \"\"\"\n",
    "A source of tension we face frequently in work is whether to get things done the quick and dirty way, or to take time to create a system to make that task more efficient later on.\n",
    "\n",
    "For example, should you:\n",
    "\n",
    "a) Manually copy and paste data from one place to another, or\n",
    "\n",
    "b) Write (and debug!) code that will automate this process?\n",
    "\n",
    "Choosing option b only makes sense if this task needs to be repeated. People who know how I work know that my preference is usually for option B even if it ends up taking more time (coding is my version of playing a slot machine). \n",
    "\n",
    "At the recent Big Data & Analytics West conference, Di Wu (Director Engineering, Coastal Community Bank) gave a presentation titled “Value Driven Architecture”, which gave me something else to think about: \n",
    "\n",
    "1. When dealing with clients and colleagues, it’s important to deliver wins at the start, not just focus on best practices and sustainability. \n",
    "2. Interim options are okay while working towards the target architecture.\n",
    "3. If you opt for interim options, it is important to not add technical debt that will create more hassle down the road. \n",
    "\n",
    "Point #1 is something the perfectionist side of me needs to remember. Point #3 is definitely something I’ll think about whenever my team members suggest a quick and dirty solution instead of an ideal solution.\n",
    "\n",
    "Have a related story to share? Post in the comments below!\n",
    "\n",
    "#bigdata\n",
    "\"\"\"\n",
    "\n",
    "template = \"\"\"\n",
    "You create content on LinkedIn with the goal of building the writer's professional brand as a data scientist who is continuously developing her skills. \n",
    "The writer is an Asian female who has her hair in a bun. Write a prompt to generate a cartoon image to accompany this LinkedIn post: {text}\n",
    "\"\"\"\n",
    "\n",
    "iteration = 3.1\n",
    "results_dict[iteration] = get_dalle_image(post, template=template, temperature=0, verbose=True)\n",
    "\n",
    "# create_linkedin_post(results_dict, iteration)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image_url': None,\n",
       " 'description': 'A source of tension we face frequently in work is whether to get things done the quick and dirty way, or to take time to create a system to make that task more efficient later on.\\n\\nFor example, should you:\\n\\na) Manually copy and paste data from one place to another, or\\n\\nb) Write (and debug!) code that will automate this process?\\n\\nChoosing option b only makes sense if this task needs to be repeated. People who know how I work know that my preference is usually for option B even if it ends up taking more time (coding is my version of playing a slot machine). \\n\\nAt the recent Big Data & Analytics West conference, Di Wu (Director Engineering, Coastal Community Bank) gave a presentation titled “Value Driven Architecture”, which gave me something else to think about: \\n\\n1. When dealing with clients and colleagues, it’s important to deliver wins at the start, not just focus on best practices and sustainability. \\n2. Interim options are okay while working towards the target architecture.\\n3. If you opt for interim options, it is important to not add technical debt that will create more hassle down the road. \\n\\nPoint #1 is something the perfectionist side of me needs to remember. Point #3 is definitely something I’ll think about whenever my team members suggest a quick and dirty solution instead of an ideal solution.\\n\\nHave a related story to share? Post in the comments below!\\n\\n#bigdata',\n",
       " 'prompt': PromptTemplate(input_variables=['text'], template=\"\\nYou create content on LinkedIn with the goal of building the writer's professional brand as a data scientist who is continuously developing her skills. \\nThe writer is an Asian female who has her hair in a bun. Write a prompt to generate a cartoon image to accompany this LinkedIn post: {text}\\n: {text}\"),\n",
       " 'image_prompt': 'Prompt for Cartoon Image: An Asian female data scientist with her hair in a bun is standing in front of a computer, debating whether to take the quick and dirty route or to take the time to create a system that will make the task more efficient in the long run.'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_dict[iteration]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Prompt for Cartoon Image: An Asian female data scientist with her hair in a bun is standing in front of a computer, debating whether to take the quick and dirty route or to take the time to create a system that will make the task more efficient in the long run.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_dict[iteration]['image_prompt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://oaidalleapiprodscus.blob.core.windows.net/private/org-4l8HUKDtXhH0T7iFErf1JSJg/user-RXAiHh79huihhcA5ecHTcKIh/img-8bqixitF3IhBeZxi6HWox6kx.png?st=2023-11-26T21%3A36%3A54Z&se=2023-11-26T23%3A36%3A54Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2023-11-26T01%3A12%3A34Z&ske=2023-11-27T01%3A12%3A34Z&sks=b&skv=2021-08-06&sig=04pl7b6vbr3y82/wuX5zohPdNB9QWGXjCBM1JD32pBw%3D']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "def create_dalle_image(prompt, n=1):\n",
    "  client = OpenAI()\n",
    "\n",
    "  response = client.images.generate(\n",
    "    model=\"dall-e-3\",\n",
    "    prompt=prompt,\n",
    "    n=n,\n",
    "  )\n",
    "\n",
    "  image_url = [item.url for item in response.data]\n",
    "  return image_url\n",
    "\n",
    "\n",
    "results_dict[iteration + 0.1] = create_dalle_image(results_dict[iteration]['image_prompt'])\n",
    "results_dict[iteration + 0.1] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iteration 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt template: \n",
      "You create content on LinkedIn with the goal of building the writer's professional brand as a data scientist who is continuously developing her skills. \n",
      "The writer is an Asian female who has her hair in a bun. Write a prompt to generate a cartoon image to accompany this LinkedIn post: {text}\n",
      ": {text}\n",
      "\n",
      "Input: A source of tension we face frequently in work is whether to get things done the quick and dirty way, or to take time to create a system to make that task more efficient later on.\n",
      "\n",
      "For example, should you:\n",
      "\n",
      "a) Manually copy and paste data from one place to another, or\n",
      "\n",
      "b) Write (and debug!) code that will automate this process?\n",
      "\n",
      "Choosing option b only makes sense if this task needs to be repeated. People who know how I work know that my preference is usually for option B even if it ends up taking more time (coding is my version of playing a slot machine). \n",
      "\n",
      "At the recent Big Data & Analytics West conference, Di Wu (Director Engineering, Coastal Community Bank) gave a presentation titled “Value Driven Architecture”, which gave me something else to think about: \n",
      "\n",
      "1. When dealing with clients and colleagues, it’s important to deliver wins at the start, not just focus on best practices and sustainability. \n",
      "2. Interim options are okay while working towards the target architecture.\n",
      "3. If you opt for interim options, it is important to not add technical debt that will create more hassle down the road. \n",
      "\n",
      "Point #1 is something the perfectionist side of me needs to remember. Point #3 is definitely something I’ll think about whenever my team members suggest a quick and dirty solution instead of an ideal solution.\n",
      "\n",
      "Have a related story to share? Post in the comments below!\n",
      "\n",
      "#bigdata\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "You create content on LinkedIn with the goal of building the writer's professional brand as a data scientist who is continuously developing her skills. \n",
      "The writer is an Asian female who has her hair in a bun. Write a prompt to generate a cartoon image to accompany this LinkedIn post: A source of tension we face frequently in work is whether to get things done the quick and dirty way, or to take time to create a system to make that task more efficient later on.\n",
      "\n",
      "For example, should you:\n",
      "\n",
      "a) Manually copy and paste data from one place to another, or\n",
      "\n",
      "b) Write (and debug!) code that will automate this process?\n",
      "\n",
      "Choosing option b only makes sense if this task needs to be repeated. People who know how I work know that my preference is usually for option B even if it ends up taking more time (coding is my version of playing a slot machine). \n",
      "\n",
      "At the recent Big Data & Analytics West conference, Di Wu (Director Engineering, Coastal Community Bank) gave a presentation titled “Value Driven Architecture”, which gave me something else to think about: \n",
      "\n",
      "1. When dealing with clients and colleagues, it’s important to deliver wins at the start, not just focus on best practices and sustainability. \n",
      "2. Interim options are okay while working towards the target architecture.\n",
      "3. If you opt for interim options, it is important to not add technical debt that will create more hassle down the road. \n",
      "\n",
      "Point #1 is something the perfectionist side of me needs to remember. Point #3 is definitely something I’ll think about whenever my team members suggest a quick and dirty solution instead of an ideal solution.\n",
      "\n",
      "Have a related story to share? Post in the comments below!\n",
      "\n",
      "#bigdata\n",
      ": A source of tension we face frequently in work is whether to get things done the quick and dirty way, or to take time to create a system to make that task more efficient later on.\n",
      "\n",
      "For example, should you:\n",
      "\n",
      "a) Manually copy and paste data from one place to another, or\n",
      "\n",
      "b) Write (and debug!) code that will automate this process?\n",
      "\n",
      "Choosing option b only makes sense if this task needs to be repeated. People who know how I work know that my preference is usually for option B even if it ends up taking more time (coding is my version of playing a slot machine). \n",
      "\n",
      "At the recent Big Data & Analytics West conference, Di Wu (Director Engineering, Coastal Community Bank) gave a presentation titled “Value Driven Architecture”, which gave me something else to think about: \n",
      "\n",
      "1. When dealing with clients and colleagues, it’s important to deliver wins at the start, not just focus on best practices and sustainability. \n",
      "2. Interim options are okay while working towards the target architecture.\n",
      "3. If you opt for interim options, it is important to not add technical debt that will create more hassle down the road. \n",
      "\n",
      "Point #1 is something the perfectionist side of me needs to remember. Point #3 is definitely something I’ll think about whenever my team members suggest a quick and dirty solution instead of an ideal solution.\n",
      "\n",
      "Have a related story to share? Post in the comments below!\n",
      "\n",
      "#bigdata\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Image prompt: Prompt for Cartoon Image: An Asian female data scientist with her hair in a bun is standing in front of a computer, debating whether to take the quick and dirty route or to take the time to create a system that will make the task more efficient in the long run.\n",
      "An error occurred on line 30 in C:\\Users\\silvh\\AppData\\Local\\Temp\\ipykernel_17212\\1940718897.py : Error code: 400 - {'error': {'code': None, 'message': 'You must provide n=1 for this model.', 'param': None, 'type': 'invalid_request_error'}}\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "import os\n",
    "# from langchain.utilities.dalle_image_generator import DallEAPIWrapper\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import OpenAI\n",
    "sys.path.append(r'C:\\Users\\silvh\\OneDrive\\lighthouse\\portfolio-projects\\langchain\\libs\\core')\n",
    "from dalle_image_generator import DallEAPIWrapper\n",
    "\n",
    "def get_dalle_image(text, model='dall-e-3', n=3, temperature=1, template=None, verbose=False, max_retries=1, max_tokens=900):\n",
    "    llm = OpenAI(\n",
    "        temperature=temperature, openai_organization=os.environ['openai_organization'],\n",
    "        max_retries=max_retries, max_tokens=max_tokens\n",
    "        )\n",
    "    text = text.strip()\n",
    "    if template:\n",
    "        template=template + ': {text}'\n",
    "    else:\n",
    "        template=\"Generate a detailed prompt to generate an image based on the following social media post: {text}\"\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"text\"],\n",
    "        template=template,\n",
    "    )\n",
    "    print(f'Prompt template: {prompt.template}')\n",
    "    print(f'\\nInput: {text}')\n",
    "    chain = LLMChain(llm=llm, prompt=prompt, verbose=verbose)\n",
    "    image_prompt = chain.run(text).strip()\n",
    "    print(f'\\nImage prompt: {image_prompt}')\n",
    "    try:\n",
    "        image_url = DallEAPIWrapper(model=model, n=n).run(image_prompt)\n",
    "    except Exception as error:\n",
    "        exc_type, exc_obj, tb = sys.exc_info()\n",
    "        f = tb.tb_frame\n",
    "        lineno = tb.tb_lineno\n",
    "        filename = f.f_code.co_filename\n",
    "        print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "        image_url = None\n",
    "\n",
    "    results = {\n",
    "        'image_url': image_url, \n",
    "        'description': text,\n",
    "        'prompt': prompt,\n",
    "        'image_prompt': image_prompt\n",
    "        }\n",
    "    return results\n",
    "\n",
    "def print_dict_values_for_key(results_dict, key, zero_indexed=False):\n",
    "    \"\"\"\n",
    "    Prints the values of a dictionary for a given key.\n",
    "\n",
    "    Parameters:\n",
    "    - results_dict (dict): Dictionary to print values for.\n",
    "    - key (str): Dictionary key to print values for.\n",
    "    - zero_indexed (bool): If True, prints the index of each value starting from 0. If False, prints the index starting from 1.\n",
    "        \"\"\"\n",
    "    for index, item in enumerate(results_dict):\n",
    "        print(f\"{index+1 if zero_indexed==False else index}: {results_dict[item].get(key, 'None').strip()}\", end='\\n\\n')\n",
    "\n",
    "def create_linkedin_post(results_dict, iteration, hashtags=['datascience', 'llm']):\n",
    "    print(results_dict[iteration]['description'])\n",
    "    print(f'\\n\\nPS: The 2 cartoons were generated by DALL-E (which obviously is not perfect yet). I asked OpenAI to generate the DALL-E prompt based on the text of the above post, and this was the result: \"{results_dict[iteration][\"image_prompt\"].strip()}\".')\n",
    "    print(f'\\nPPS: If you really want to know, the prompt template I used to generate the DALL-E prompt (with the help of the LangChain `LLMChain` class) was as follows: \"{results_dict[iteration][\"prompt\"].template[:-8].strip()}\"')\n",
    "    print(f'\\n\\n{\"\".join([f\"#{tag} \" for tag in hashtags])}')\n",
    "\n",
    "post = \"\"\"\n",
    "A source of tension we face frequently in work is whether to get things done the quick and dirty way, or to take time to create a system to make that task more efficient later on.\n",
    "\n",
    "For example, should you:\n",
    "\n",
    "a) Manually copy and paste data from one place to another, or\n",
    "\n",
    "b) Write (and debug!) code that will automate this process?\n",
    "\n",
    "Choosing option b only makes sense if this task needs to be repeated. People who know how I work know that my preference is usually for option B even if it ends up taking more time (coding is my version of playing a slot machine). \n",
    "\n",
    "At the recent Big Data & Analytics West conference, Di Wu (Director Engineering, Coastal Community Bank) gave a presentation titled “Value Driven Architecture”, which gave me something else to think about: \n",
    "\n",
    "1. When dealing with clients and colleagues, it’s important to deliver wins at the start, not just focus on best practices and sustainability. \n",
    "2. Interim options are okay while working towards the target architecture.\n",
    "3. If you opt for interim options, it is important to not add technical debt that will create more hassle down the road. \n",
    "\n",
    "Point #1 is something the perfectionist side of me needs to remember. Point #3 is definitely something I’ll think about whenever my team members suggest a quick and dirty solution instead of an ideal solution.\n",
    "\n",
    "Have a related story to share? Post in the comments below!\n",
    "\n",
    "#bigdata\n",
    "\"\"\"\n",
    "\n",
    "template = \"\"\"\n",
    "You create content on LinkedIn with the goal of building the writer's professional brand as a data scientist who is continuously developing her skills. \n",
    "The writer is an Asian female who has her hair in a bun. Write a prompt to generate a cartoon image to accompany this LinkedIn post: {text}\n",
    "\"\"\"\n",
    "\n",
    "iteration = 4\n",
    "results_dict[iteration] = get_dalle_image(post, template=template, temperature=0, verbose=True)\n",
    "\n",
    "# create_linkedin_post(results_dict, iteration)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt template: \n",
      "You create content on LinkedIn with the goal of building the writer's professional brand as a data scientist who is continuously developing her skills. \n",
      "The writer is an Asian female who has her hair in a bun. Write a prompt to generate a cartoon image to accompany this LinkedIn post: {text}\n",
      ": {text}\n",
      "\n",
      "Input: A source of tension we face frequently in work is whether to get things done the quick and dirty way, or to take time to create a system to make that task more efficient later on.\n",
      "\n",
      "For example, should you:\n",
      "\n",
      "a) Manually copy and paste data from one place to another, or\n",
      "\n",
      "b) Write (and debug!) code that will automate this process?\n",
      "\n",
      "Choosing option b only makes sense if this task needs to be repeated. People who know how I work know that my preference is usually for option B even if it ends up taking more time (coding is my version of playing a slot machine). \n",
      "\n",
      "At the recent Big Data & Analytics West conference, Di Wu (Director Engineering, Coastal Community Bank) gave a presentation titled “Value Driven Architecture”, which gave me something else to think about: \n",
      "\n",
      "1. When dealing with clients and colleagues, it’s important to deliver wins at the start, not just focus on best practices and sustainability. \n",
      "2. Interim options are okay while working towards the target architecture.\n",
      "3. If you opt for interim options, it is important to not add technical debt that will create more hassle down the road. \n",
      "\n",
      "Point #1 is something the perfectionist side of me needs to remember. Point #3 is definitely something I’ll think about whenever my team members suggest a quick and dirty solution instead of an ideal solution.\n",
      "\n",
      "Have a related story to share? Post in the comments below!\n",
      "\n",
      "#bigdata\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "You create content on LinkedIn with the goal of building the writer's professional brand as a data scientist who is continuously developing her skills. \n",
      "The writer is an Asian female who has her hair in a bun. Write a prompt to generate a cartoon image to accompany this LinkedIn post: A source of tension we face frequently in work is whether to get things done the quick and dirty way, or to take time to create a system to make that task more efficient later on.\n",
      "\n",
      "For example, should you:\n",
      "\n",
      "a) Manually copy and paste data from one place to another, or\n",
      "\n",
      "b) Write (and debug!) code that will automate this process?\n",
      "\n",
      "Choosing option b only makes sense if this task needs to be repeated. People who know how I work know that my preference is usually for option B even if it ends up taking more time (coding is my version of playing a slot machine). \n",
      "\n",
      "At the recent Big Data & Analytics West conference, Di Wu (Director Engineering, Coastal Community Bank) gave a presentation titled “Value Driven Architecture”, which gave me something else to think about: \n",
      "\n",
      "1. When dealing with clients and colleagues, it’s important to deliver wins at the start, not just focus on best practices and sustainability. \n",
      "2. Interim options are okay while working towards the target architecture.\n",
      "3. If you opt for interim options, it is important to not add technical debt that will create more hassle down the road. \n",
      "\n",
      "Point #1 is something the perfectionist side of me needs to remember. Point #3 is definitely something I’ll think about whenever my team members suggest a quick and dirty solution instead of an ideal solution.\n",
      "\n",
      "Have a related story to share? Post in the comments below!\n",
      "\n",
      "#bigdata\n",
      ": A source of tension we face frequently in work is whether to get things done the quick and dirty way, or to take time to create a system to make that task more efficient later on.\n",
      "\n",
      "For example, should you:\n",
      "\n",
      "a) Manually copy and paste data from one place to another, or\n",
      "\n",
      "b) Write (and debug!) code that will automate this process?\n",
      "\n",
      "Choosing option b only makes sense if this task needs to be repeated. People who know how I work know that my preference is usually for option B even if it ends up taking more time (coding is my version of playing a slot machine). \n",
      "\n",
      "At the recent Big Data & Analytics West conference, Di Wu (Director Engineering, Coastal Community Bank) gave a presentation titled “Value Driven Architecture”, which gave me something else to think about: \n",
      "\n",
      "1. When dealing with clients and colleagues, it’s important to deliver wins at the start, not just focus on best practices and sustainability. \n",
      "2. Interim options are okay while working towards the target architecture.\n",
      "3. If you opt for interim options, it is important to not add technical debt that will create more hassle down the road. \n",
      "\n",
      "Point #1 is something the perfectionist side of me needs to remember. Point #3 is definitely something I’ll think about whenever my team members suggest a quick and dirty solution instead of an ideal solution.\n",
      "\n",
      "Have a related story to share? Post in the comments below!\n",
      "\n",
      "#bigdata\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Image prompt: Prompt: An Asian female data scientist with her hair in a bun is sitting at her desk, deep in thought. She is considering the trade-off between taking the quick and dirty route or taking the time to create a system that will make the task more efficient in the long run.\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "import os\n",
    "# from langchain.utilities.dalle_image_generator import DallEAPIWrapper\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import OpenAI\n",
    "sys.path.append(r'C:\\Users\\silvh\\OneDrive\\lighthouse\\portfolio-projects\\langchain\\libs\\core')\n",
    "from dalle_image_generator import DallEAPIWrapper\n",
    "\n",
    "def get_dalle_image(text, model='dall-e-3', n=1, temperature=1, template=None, verbose=False, max_retries=1, max_tokens=900):\n",
    "    llm = OpenAI(\n",
    "        temperature=temperature, openai_organization=os.environ['openai_organization'],\n",
    "        max_retries=max_retries, max_tokens=max_tokens\n",
    "        )\n",
    "    text = text.strip()\n",
    "    if template:\n",
    "        template=template + ': {text}'\n",
    "    else:\n",
    "        template=\"Generate a detailed prompt to generate an image based on the following social media post: {text}\"\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"text\"],\n",
    "        template=template,\n",
    "    )\n",
    "    print(f'Prompt template: {prompt.template}')\n",
    "    print(f'\\nInput: {text}')\n",
    "    chain = LLMChain(llm=llm, prompt=prompt, verbose=verbose)\n",
    "    image_prompt = chain.run(text).strip()\n",
    "    print(f'\\nImage prompt: {image_prompt}')\n",
    "    try:\n",
    "        image_url = DallEAPIWrapper(model=model, n=n).run(image_prompt)\n",
    "    except Exception as error:\n",
    "        exc_type, exc_obj, tb = sys.exc_info()\n",
    "        f = tb.tb_frame\n",
    "        lineno = tb.tb_lineno\n",
    "        filename = f.f_code.co_filename\n",
    "        print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "        image_url = None\n",
    "\n",
    "    results = {\n",
    "        'image_url': image_url, \n",
    "        'description': text,\n",
    "        'prompt': prompt,\n",
    "        'image_prompt': image_prompt\n",
    "        }\n",
    "    return results\n",
    "\n",
    "def print_dict_values_for_key(results_dict, key, zero_indexed=False):\n",
    "    \"\"\"\n",
    "    Prints the values of a dictionary for a given key.\n",
    "\n",
    "    Parameters:\n",
    "    - results_dict (dict): Dictionary to print values for.\n",
    "    - key (str): Dictionary key to print values for.\n",
    "    - zero_indexed (bool): If True, prints the index of each value starting from 0. If False, prints the index starting from 1.\n",
    "        \"\"\"\n",
    "    for index, item in enumerate(results_dict):\n",
    "        print(f\"{index+1 if zero_indexed==False else index}: {results_dict[item].get(key, 'None').strip()}\", end='\\n\\n')\n",
    "\n",
    "def create_linkedin_post(results_dict, iteration, hashtags=['datascience', 'llm']):\n",
    "    print(results_dict[iteration]['description'])\n",
    "    print(f'\\n\\nPS: The 2 cartoons were generated by DALL-E (which obviously is not perfect yet). I asked OpenAI to generate the DALL-E prompt based on the text of the above post, and this was the result: \"{results_dict[iteration][\"image_prompt\"].strip()}\".')\n",
    "    print(f'\\nPPS: If you really want to know, the prompt template I used to generate the DALL-E prompt (with the help of the LangChain `LLMChain` class) was as follows: \"{results_dict[iteration][\"prompt\"].template[:-8].strip()}\"')\n",
    "    print(f'\\n\\n{\"\".join([f\"#{tag} \" for tag in hashtags])}')\n",
    "\n",
    "post = \"\"\"\n",
    "A source of tension we face frequently in work is whether to get things done the quick and dirty way, or to take time to create a system to make that task more efficient later on.\n",
    "\n",
    "For example, should you:\n",
    "\n",
    "a) Manually copy and paste data from one place to another, or\n",
    "\n",
    "b) Write (and debug!) code that will automate this process?\n",
    "\n",
    "Choosing option b only makes sense if this task needs to be repeated. People who know how I work know that my preference is usually for option B even if it ends up taking more time (coding is my version of playing a slot machine). \n",
    "\n",
    "At the recent Big Data & Analytics West conference, Di Wu (Director Engineering, Coastal Community Bank) gave a presentation titled “Value Driven Architecture”, which gave me something else to think about: \n",
    "\n",
    "1. When dealing with clients and colleagues, it’s important to deliver wins at the start, not just focus on best practices and sustainability. \n",
    "2. Interim options are okay while working towards the target architecture.\n",
    "3. If you opt for interim options, it is important to not add technical debt that will create more hassle down the road. \n",
    "\n",
    "Point #1 is something the perfectionist side of me needs to remember. Point #3 is definitely something I’ll think about whenever my team members suggest a quick and dirty solution instead of an ideal solution.\n",
    "\n",
    "Have a related story to share? Post in the comments below!\n",
    "\n",
    "#bigdata\n",
    "\"\"\"\n",
    "\n",
    "template = \"\"\"\n",
    "You create content on LinkedIn with the goal of building the writer's professional brand as a data scientist who is continuously developing her skills. \n",
    "The writer is an Asian female who has her hair in a bun. Write a prompt to generate a cartoon image to accompany this LinkedIn post: {text}\n",
    "\"\"\"\n",
    "\n",
    "iteration = 4\n",
    "results_dict[iteration] = get_dalle_image(post, template=template, temperature=0, verbose=True)\n",
    "\n",
    "# create_linkedin_post(results_dict, iteration)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image_url': 'https://oaidalleapiprodscus.blob.core.windows.net/private/org-4l8HUKDtXhH0T7iFErf1JSJg/user-RXAiHh79huihhcA5ecHTcKIh/img-tSTrAeenedE1uUjdTP4nosAa.png?st=2023-11-26T21%3A43%3A42Z&se=2023-11-26T23%3A43%3A42Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2023-11-26T21%3A00%3A16Z&ske=2023-11-27T21%3A00%3A16Z&sks=b&skv=2021-08-06&sig=aVr%2B02xDfSVbXHkoXJxLl8xKH/ZT3xQ28QMGCLib1vs%3D',\n",
       " 'description': 'A source of tension we face frequently in work is whether to get things done the quick and dirty way, or to take time to create a system to make that task more efficient later on.\\n\\nFor example, should you:\\n\\na) Manually copy and paste data from one place to another, or\\n\\nb) Write (and debug!) code that will automate this process?\\n\\nChoosing option b only makes sense if this task needs to be repeated. People who know how I work know that my preference is usually for option B even if it ends up taking more time (coding is my version of playing a slot machine). \\n\\nAt the recent Big Data & Analytics West conference, Di Wu (Director Engineering, Coastal Community Bank) gave a presentation titled “Value Driven Architecture”, which gave me something else to think about: \\n\\n1. When dealing with clients and colleagues, it’s important to deliver wins at the start, not just focus on best practices and sustainability. \\n2. Interim options are okay while working towards the target architecture.\\n3. If you opt for interim options, it is important to not add technical debt that will create more hassle down the road. \\n\\nPoint #1 is something the perfectionist side of me needs to remember. Point #3 is definitely something I’ll think about whenever my team members suggest a quick and dirty solution instead of an ideal solution.\\n\\nHave a related story to share? Post in the comments below!\\n\\n#bigdata',\n",
       " 'prompt': PromptTemplate(input_variables=['text'], template=\"\\nYou create content on LinkedIn with the goal of building the writer's professional brand as a data scientist who is continuously developing her skills. \\nThe writer is an Asian female who has her hair in a bun. Write a prompt to generate a cartoon image to accompany this LinkedIn post: {text}\\n: {text}\"),\n",
       " 'image_prompt': 'Prompt: An Asian female data scientist with her hair in a bun is sitting at her desk, deep in thought. She is considering the trade-off between taking the quick and dirty route or taking the time to create a system that will make the task more efficient in the long run.'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_dict[iteration]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### # 4.2 ** Final version** update `create_linkedin_post`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A source of tension we face frequently in work is whether to get things done the quick and dirty way, or to take time to create a system to make that task more efficient later on.\n",
      "\n",
      "For example, should you:\n",
      "\n",
      "a) Manually copy and paste data from one place to another, or\n",
      "\n",
      "b) Write (and debug!) code that will automate this process?\n",
      "\n",
      "Choosing option b only makes sense if this task needs to be repeated. People who know how I work know that my preference is usually for option B even if it ends up taking more time (coding is my version of playing a slot machine). \n",
      "\n",
      "At the recent Big Data & Analytics West conference, Di Wu (Director Engineering, Coastal Community Bank) gave a presentation titled “Value Driven Architecture”, which gave me something else to think about: \n",
      "\n",
      "1. When dealing with clients and colleagues, it’s important to deliver wins at the start, not just focus on best practices and sustainability. \n",
      "2. Interim options are okay while working towards the target architecture.\n",
      "3. If you opt for interim options, it is important to not add technical debt that will create more hassle down the road. \n",
      "\n",
      "Point #1 is something the perfectionist side of me needs to remember. Point #3 is definitely something I’ll think about whenever my team members suggest a quick and dirty solution instead of an ideal solution.\n",
      "\n",
      "Have a related story to share? Post in the comments below!\n",
      "\n",
      "#bigdata\n",
      "\n",
      "\n",
      "PS: The image was generated by Dall-E 3 (which obviously is not perfect yet). I asked OpenAI to generate the DALL-E prompt based on the text of the above post, and this was the result: \"Prompt: An Asian female data scientist with her hair in a bun is sitting at her desk, deep in thought. She is considering the trade-off between taking the quick and dirty route or taking the time to create a system that will make the task more efficient in the long run.\".\n",
      "\n",
      "PPS: If you really want to know, the prompt template I used to generate the DALL-E prompt (with the help of the LangChain `LLMChain` class) was as follows: \"You create content on LinkedIn with the goal of building the writer's professional brand as a data scientist who is continuously developing her skills. \n",
      "The writer is an Asian female who has her hair in a bun. Write a prompt to generate a cartoon image to accompany this LinkedIn post: {text}\"\n",
      "\n",
      "\n",
      "#datascience #llm \n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "import os\n",
    "# from langchain.utilities.dalle_image_generator import DallEAPIWrapper\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import OpenAI\n",
    "# Update DallEAPIWrapper script to fix error in Langchain package\n",
    "sys.path.append(r'C:\\Users\\silvh\\OneDrive\\lighthouse\\portfolio-projects\\langchain\\libs\\core') \n",
    "from dalle_image_generator import DallEAPIWrapper\n",
    "\n",
    "def get_dalle_image(text, model='dall-e-3', n=1, temperature=1, template=None, verbose=False, max_retries=1, max_tokens=900):\n",
    "    llm = OpenAI(\n",
    "        temperature=temperature, openai_organization=os.environ['openai_organization'],\n",
    "        max_retries=max_retries, max_tokens=max_tokens\n",
    "        )\n",
    "    text = text.strip()\n",
    "    if template:\n",
    "        template=template + ': {text}'\n",
    "    else:\n",
    "        template=\"Generate a detailed prompt to generate an image based on the following social media post: {text}\"\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"text\"],\n",
    "        template=template,\n",
    "    )\n",
    "    print(f'Prompt template: {prompt.template}')\n",
    "    print(f'\\nInput: {text}')\n",
    "    chain = LLMChain(llm=llm, prompt=prompt, verbose=verbose)\n",
    "    image_prompt = chain.run(text).strip()\n",
    "    print(f'\\nImage prompt: {image_prompt}')\n",
    "    try:\n",
    "        image_url = DallEAPIWrapper(model=model, n=n).run(image_prompt)\n",
    "    except Exception as error:\n",
    "        exc_type, exc_obj, tb = sys.exc_info()\n",
    "        f = tb.tb_frame\n",
    "        lineno = tb.tb_lineno\n",
    "        filename = f.f_code.co_filename\n",
    "        print(\"An error occurred on line\", lineno, \"in\", filename, \":\", error)\n",
    "        image_url = None\n",
    "\n",
    "    results = {\n",
    "        'image_url': image_url, \n",
    "        'description': text,\n",
    "        'prompt': prompt,\n",
    "        'image_prompt': image_prompt\n",
    "        }\n",
    "    return results\n",
    "\n",
    "def print_dict_values_for_key(results_dict, key, zero_indexed=False):\n",
    "    \"\"\"\n",
    "    Prints the values of a dictionary for a given key.\n",
    "\n",
    "    Parameters:\n",
    "    - results_dict (dict): Dictionary to print values for.\n",
    "    - key (str): Dictionary key to print values for.\n",
    "    - zero_indexed (bool): If True, prints the index of each value starting from 0. If False, prints the index starting from 1.\n",
    "        \"\"\"\n",
    "    for index, item in enumerate(results_dict):\n",
    "        print(f\"{index+1 if zero_indexed==False else index}: {results_dict[item].get(key, 'None').strip()}\", end='\\n\\n')\n",
    "\n",
    "def create_linkedin_post(results_dict, iteration, model='Dall-E 3', hashtags=['datascience', 'llm']):\n",
    "    print(results_dict[iteration]['description'])\n",
    "    print(f'\\n\\nPS: The image was generated by {model} (which obviously is not perfect yet). I asked OpenAI to generate the DALL-E prompt based on the text of the above post, and this was the result: \"{results_dict[iteration][\"image_prompt\"].strip()}\".')\n",
    "    print(f'\\nPPS: If you really want to know, the prompt template I used to generate the DALL-E prompt (with the help of the LangChain `LLMChain` class) was as follows: \"{results_dict[iteration][\"prompt\"].template[:-8].strip()}\"')\n",
    "    print(f'\\n\\n{\"\".join([f\"#{tag} \" for tag in hashtags])}')\n",
    "\n",
    "post = \"\"\"\n",
    "A source of tension we face frequently in work is whether to get things done the quick and dirty way, or to take time to create a system to make that task more efficient later on.\n",
    "\n",
    "For example, should you:\n",
    "\n",
    "a) Manually copy and paste data from one place to another, or\n",
    "\n",
    "b) Write (and debug!) code that will automate this process?\n",
    "\n",
    "Choosing option b only makes sense if this task needs to be repeated. People who know how I work know that my preference is usually for option B even if it ends up taking more time (coding is my version of playing a slot machine). \n",
    "\n",
    "At the recent Big Data & Analytics West conference, Di Wu (Director Engineering, Coastal Community Bank) gave a presentation titled “Value Driven Architecture”, which gave me something else to think about: \n",
    "\n",
    "1. When dealing with clients and colleagues, it’s important to deliver wins at the start, not just focus on best practices and sustainability. \n",
    "2. Interim options are okay while working towards the target architecture.\n",
    "3. If you opt for interim options, it is important to not add technical debt that will create more hassle down the road. \n",
    "\n",
    "Point #1 is something the perfectionist side of me needs to remember. Point #3 is definitely something I’ll think about whenever my team members suggest a quick and dirty solution instead of an ideal solution.\n",
    "\n",
    "Have a related story to share? Post in the comments below!\n",
    "\n",
    "#bigdata\n",
    "\"\"\"\n",
    "\n",
    "template = \"\"\"\n",
    "You create content on LinkedIn with the goal of building the writer's professional brand as a data scientist who is continuously developing her skills. \n",
    "The writer is an Asian female who has her hair in a bun. Write a prompt to generate a cartoon image to accompany this LinkedIn post: {text}\n",
    "\"\"\"\n",
    "\n",
    "iteration = 4\n",
    "# results_dict[iteration] = get_dalle_image(post, template=template, temperature=0, verbose=True)\n",
    "\n",
    "create_linkedin_post(results_dict, iteration)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2023-12-01 Stability AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copied from https://platform.stability.ai/docs/api-reference#tag/v1generation/operation/textToImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import os\n",
    "import requests\n",
    "\n",
    "engine_id = \"stable-diffusion-v1-6\"\n",
    "api_host = os.getenv('API_HOST', 'https://api.stability.ai')\n",
    "api_key = os.getenv(\"STABILITY_API_KEY\")\n",
    "\n",
    "if api_key is None:\n",
    "    raise Exception(\"Missing Stability API key.\")\n",
    "\n",
    "response = requests.post(\n",
    "    f\"{api_host}/v1/generation/{engine_id}/text-to-image\",\n",
    "    headers={\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Accept\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {api_key}\"\n",
    "    },\n",
    "    json={\n",
    "        \"text_prompts\": [\n",
    "            {\n",
    "                \"text\": \"A lighthouse on a cliff\"\n",
    "            }\n",
    "        ],\n",
    "        \"cfg_scale\": 7,\n",
    "        \"height\": 1024,\n",
    "        \"width\": 1024,\n",
    "        \"samples\": 1,\n",
    "        \"steps\": 30,\n",
    "    },\n",
    ")\n",
    "\n",
    "if response.status_code != 200:\n",
    "    raise Exception(\"Non-200 response: \" + str(response.text))\n",
    "\n",
    "data = response.json()\n",
    "\n",
    "for i, image in enumerate(data[\"artifacts\"]):\n",
    "    with open(f\"./out/v1_txt2img_{i}.png\", \"wb\") as f:\n",
    "        f.write(base64.b64decode(image[\"base64\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "api_host = os.getenv('API_HOST', 'https://api.stability.ai')\n",
    "url = f\"{api_host}/v1/engines/list\"\n",
    "\n",
    "api_key = os.getenv(\"STABILITY_API_KEY\")\n",
    "if api_key is None:\n",
    "    raise Exception(\"Missing Stability API key.\")\n",
    "\n",
    "response = requests.get(url, headers={\n",
    "    \"Authorization\": f\"Bearer {api_key}\"\n",
    "})\n",
    "\n",
    "if response.status_code != 200:\n",
    "    raise Exception(\"Non-200 response: \" + str(response.text))\n",
    "\n",
    "# Do something with the payload...\n",
    "payload = response.json()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## convert into a function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'description': 'Real-ESRGAN_x2plus upscaler model',\n",
       "  'id': 'esrgan-v1-x2plus',\n",
       "  'name': 'Real-ESRGAN x2',\n",
       "  'type': 'PICTURE'},\n",
       " {'description': 'Stability-AI Stable Diffusion XL v0.9',\n",
       "  'id': 'stable-diffusion-xl-1024-v0-9',\n",
       "  'name': 'Stable Diffusion XL v0.9',\n",
       "  'type': 'PICTURE'},\n",
       " {'description': 'Stability-AI Stable Diffusion XL v1.0',\n",
       "  'id': 'stable-diffusion-xl-1024-v1-0',\n",
       "  'name': 'Stable Diffusion XL v1.0',\n",
       "  'type': 'PICTURE'},\n",
       " {'description': 'Stability-AI Stable Diffusion v1.6',\n",
       "  'id': 'stable-diffusion-v1-6',\n",
       "  'name': 'Stable Diffusion v1.6',\n",
       "  'type': 'PICTURE'},\n",
       " {'description': 'Stability-AI Stable Diffusion v2.1',\n",
       "  'id': 'stable-diffusion-512-v2-1',\n",
       "  'name': 'Stable Diffusion v2.1',\n",
       "  'type': 'PICTURE'},\n",
       " {'description': 'Stability-AI Stable Diffusion XL Beta v2.2.2',\n",
       "  'id': 'stable-diffusion-xl-beta-v2-2-2',\n",
       "  'name': 'Stable Diffusion v2.2.2-XL Beta',\n",
       "  'type': 'PICTURE'}]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import base64\n",
    "import os\n",
    "import requests\n",
    "\n",
    "def list_stability_engines():\n",
    "    \"\"\"\n",
    "    https://platform.stability.ai/pricing\n",
    "    \"\"\"\n",
    "    api_host = os.getenv('API_HOST', 'https://api.stability.ai')\n",
    "    url = f\"{api_host}/v1/engines/list\"\n",
    "\n",
    "    api_key = os.getenv(\"STABILITY_API_KEY\")\n",
    "    if api_key is None:\n",
    "        raise Exception(\"Missing Stability API key.\")\n",
    "\n",
    "    response = requests.get(url, headers={\n",
    "        \"Authorization\": f\"Bearer {api_key}\"\n",
    "    })\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(\"Non-200 response: \" + str(response.text))\n",
    "\n",
    "    # Do something with the payload...\n",
    "    payload = response.json()\n",
    "    return payload\n",
    "\n",
    "def generate_stability_image(text, engine_id = \"stable-diffusion-v1-5\"):\n",
    "    \n",
    "    api_host = os.getenv('API_HOST', 'https://api.stability.ai')\n",
    "    api_key = os.getenv(\"STABILITY_API_KEY\")\n",
    "\n",
    "    if api_key is None:\n",
    "        raise Exception(\"Missing Stability API key.\")\n",
    "\n",
    "    response = requests.post(\n",
    "        f\"{api_host}/v1/generation/{engine_id}/text-to-image\",\n",
    "        headers={\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"Accept\": \"application/json\",\n",
    "            \"Authorization\": f\"Bearer {api_key}\"\n",
    "        },\n",
    "        json={\n",
    "            \"text_prompts\": [\n",
    "                {\n",
    "                    \"text\": text\n",
    "                }\n",
    "            ],\n",
    "            \"cfg_scale\": 7,\n",
    "            \"height\": 512,\n",
    "            \"width\": 512,\n",
    "            \"samples\": 1,\n",
    "            \"steps\": 30,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(\"Non-200 response: \" + str(response.text))\n",
    "\n",
    "    data = response.json()\n",
    "\n",
    "    for i, image in enumerate(data[\"artifacts\"]):\n",
    "        with open(f\"./out/v1_txt2img_{i}.png\", \"wb\") as f:\n",
    "            f.write(base64.b64decode(image[\"base64\"]))\n",
    "\n",
    "# generate_stability_image(\"A lighthouse on a cliff\")\n",
    "list_stability_engines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## iteration 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image saved as ../ai_images//stable-diffusion-v1-6_2023-12-02_2150_0.png\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "import os\n",
    "import requests\n",
    "from datetime import datetime\n",
    "\n",
    "def list_stability_engines():\n",
    "    \"\"\"\n",
    "    https://platform.stability.ai/pricing\n",
    "    \"\"\"\n",
    "    api_host = os.getenv('API_HOST', 'https://api.stability.ai')\n",
    "    url = f\"{api_host}/v1/engines/list\"\n",
    "\n",
    "    api_key = os.getenv(\"STABILITY_API_KEY\")\n",
    "    if api_key is None:\n",
    "        raise Exception(\"Missing Stability API key.\")\n",
    "\n",
    "    response = requests.get(url, headers={\n",
    "        \"Authorization\": f\"Bearer {api_key}\"\n",
    "    })\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(\"Non-200 response: \" + str(response.text))\n",
    "\n",
    "    # Do something with the payload...\n",
    "    payload = response.json()\n",
    "    return payload\n",
    "\n",
    "def generate_stability_image(\n",
    "        prompt, engine_id = \"stable-diffusion-v1-6\",\n",
    "        filename=None, filepath='../ai_images/'\n",
    "        ):\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d_%H%M\")\n",
    "    \n",
    "    api_host = 'https://api.stability.ai'\n",
    "    api_key = os.getenv(\"STABILITY_API_KEY\")\n",
    "\n",
    "    if api_key is None:\n",
    "        raise Exception(\"Missing Stability API key.\")\n",
    "\n",
    "    response = requests.post(\n",
    "        f\"{api_host}/v1/generation/{engine_id}/text-to-image\",\n",
    "        headers={\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"Accept\": \"application/json\",\n",
    "            \"Authorization\": f\"Bearer {api_key}\"\n",
    "        },\n",
    "        json={\n",
    "            \"text_prompts\": [\n",
    "                {\n",
    "                    \"text\": prompt\n",
    "                }\n",
    "            ]#,\n",
    "            # \"cfg_scale\": 7,\n",
    "            # \"height\": 512,\n",
    "            # \"width\": 512,\n",
    "            # \"samples\": 1,\n",
    "            # \"steps\": 30,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(\"Non-200 response: \" + str(response.text))\n",
    "\n",
    "    data = response.json()\n",
    "\n",
    "    for i, image in enumerate(data[\"artifacts\"]):\n",
    "        full_filename = f\"{filepath}/{filename if filename else engine_id}_{timestamp}_{i}.png\"\n",
    "        with open(full_filename, \"wb\") as f:\n",
    "            f.write(base64.b64decode(image[\"base64\"]))\n",
    "        print(f'Image saved as {full_filename}')\n",
    "\n",
    "prompt = \"\"\"\n",
    "A cartoon of a female data scientist with her hair in a bun.\n",
    "\"\"\"\n",
    "generate_stability_image(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image saved as ../ai_images//stable-diffusion-v1-6_2023-12-02_2210_0.png\n",
      "Image saved as ../ai_images//stable-diffusion-v1-6_2023-12-02_2210_0.png_1.png\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "import os\n",
    "import requests\n",
    "from datetime import datetime\n",
    "\n",
    "def list_stability_engines():\n",
    "    \"\"\"\n",
    "    https://platform.stability.ai/pricing\n",
    "    \"\"\"\n",
    "    api_host = os.getenv('API_HOST', 'https://api.stability.ai')\n",
    "    url = f\"{api_host}/v1/engines/list\"\n",
    "\n",
    "    api_key = os.getenv(\"STABILITY_API_KEY\")\n",
    "    if api_key is None:\n",
    "        raise Exception(\"Missing Stability API key.\")\n",
    "\n",
    "    response = requests.get(url, headers={\n",
    "        \"Authorization\": f\"Bearer {api_key}\"\n",
    "    })\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(\"Non-200 response: \" + str(response.text))\n",
    "\n",
    "    # Do something with the payload...\n",
    "    payload = response.json()\n",
    "    return payload\n",
    "\n",
    "def generate_stability_image(\n",
    "        prompt, n_images=1,\n",
    "        engine_id = \"stable-diffusion-v1-6\",\n",
    "        filename=None, filepath='../ai_images/'\n",
    "        ):\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d_%H%M\")\n",
    "    \n",
    "    api_host = 'https://api.stability.ai'\n",
    "    api_key = os.getenv(\"STABILITY_API_KEY\")\n",
    "\n",
    "    if api_key is None:\n",
    "        raise Exception(\"Missing Stability API key.\")\n",
    "\n",
    "    response = requests.post(\n",
    "        f\"{api_host}/v1/generation/{engine_id}/text-to-image\",\n",
    "        headers={\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"Accept\": \"application/json\",\n",
    "            \"Authorization\": f\"Bearer {api_key}\"\n",
    "        },\n",
    "        json={\n",
    "            \"text_prompts\": [\n",
    "                {\n",
    "                    \"text\": prompt\n",
    "                }\n",
    "            ],\n",
    "            \"samples\": n_images,\n",
    "            # \"cfg_scale\": 7,\n",
    "            # \"height\": 512,\n",
    "            # \"width\": 512,\n",
    "            # \"steps\": 30,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(\"Non-200 response: \" + str(response.text))\n",
    "\n",
    "    data = response.json()\n",
    "    full_filename = f\"{filepath}/{filename if filename else engine_id}_{timestamp}\"\n",
    "    if len(data[\"artifacts\"]) == 1:\n",
    "        full_filename += '.png'\n",
    "        with open(full_filename, \"wb\") as f:\n",
    "            f.write(base64.b64decode(image[\"base64\"]))\n",
    "        print(f'Image saved as {full_filename}')\n",
    "    elif len(data[\"artifacts\"]) > 1:\n",
    "        for i, image in enumerate(data[\"artifacts\"]):\n",
    "            full_filename += f'_{i}.png'\n",
    "            with open(full_filename, \"wb\") as f:\n",
    "                f.write(base64.b64decode(image[\"base64\"]))\n",
    "            print(f'Image saved as {full_filename}')\n",
    "\n",
    "prompt = \"\"\"\n",
    "A cartoon of an Asian female data scientist with her hair in a bun.\n",
    "\"\"\"\n",
    "generate_stability_image(prompt, n_images=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image saved as ../ai_images//stable-diffusion-v1-6_2023-12-02_2214_0.png\n",
      "Image saved as ../ai_images//stable-diffusion-v1-6_2023-12-02_2214_1.png\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "import os\n",
    "import requests\n",
    "from datetime import datetime\n",
    "\n",
    "def list_stability_engines():\n",
    "    \"\"\"\n",
    "    https://platform.stability.ai/pricing\n",
    "    \"\"\"\n",
    "    api_host = os.getenv('API_HOST', 'https://api.stability.ai')\n",
    "    url = f\"{api_host}/v1/engines/list\"\n",
    "\n",
    "    api_key = os.getenv(\"STABILITY_API_KEY\")\n",
    "    if api_key is None:\n",
    "        raise Exception(\"Missing Stability API key.\")\n",
    "\n",
    "    response = requests.get(url, headers={\n",
    "        \"Authorization\": f\"Bearer {api_key}\"\n",
    "    })\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(\"Non-200 response: \" + str(response.text))\n",
    "\n",
    "    # Do something with the payload...\n",
    "    payload = response.json()\n",
    "    return payload\n",
    "\n",
    "def generate_stability_image(\n",
    "        prompt, n_images=1,\n",
    "        engine_id = \"stable-diffusion-v1-6\",\n",
    "        filename=None, filepath='../ai_images/'\n",
    "        ):\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d_%H%M\")\n",
    "    \n",
    "    api_host = 'https://api.stability.ai'\n",
    "    api_key = os.getenv(\"STABILITY_API_KEY\")\n",
    "\n",
    "    if api_key is None:\n",
    "        raise Exception(\"Missing Stability API key.\")\n",
    "\n",
    "    response = requests.post(\n",
    "        f\"{api_host}/v1/generation/{engine_id}/text-to-image\",\n",
    "        headers={\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"Accept\": \"application/json\",\n",
    "            \"Authorization\": f\"Bearer {api_key}\"\n",
    "        },\n",
    "        json={\n",
    "            \"text_prompts\": [\n",
    "                {\n",
    "                    \"text\": prompt\n",
    "                }\n",
    "            ],\n",
    "            \"samples\": n_images,\n",
    "            # \"cfg_scale\": 7,\n",
    "            # \"height\": 512,\n",
    "            # \"width\": 512,\n",
    "            # \"steps\": 30,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(\"Non-200 response: \" + str(response.text))\n",
    "\n",
    "    data = response.json()\n",
    "    if len(data[\"artifacts\"]) == 1:\n",
    "        full_filename = f\"{filepath}/{filename if filename else engine_id}_{timestamp}.png\"\n",
    "        with open(full_filename, \"wb\") as f:\n",
    "            f.write(base64.b64decode(image[\"base64\"]))\n",
    "        print(f'Image saved as {full_filename}')\n",
    "    elif len(data[\"artifacts\"]) > 1:\n",
    "        for i, image in enumerate(data[\"artifacts\"]):\n",
    "            full_filename = f\"{filepath}/{filename if filename else engine_id}_{timestamp}_{i}.png\"\n",
    "            with open(full_filename, \"wb\") as f:\n",
    "                f.write(base64.b64decode(image[\"base64\"]))\n",
    "            print(f'Image saved as {full_filename}')\n",
    "\n",
    "prompt = \"\"\"\n",
    "Data scientists in a session at a tech conference.\n",
    "\"\"\"\n",
    "generate_stability_image(prompt, n_images=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *End of Page*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "11938c6bc6919ae2720b4d5011047913343b08a43b18698fd82dedb0d4417594"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
